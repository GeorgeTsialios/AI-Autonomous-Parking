<!DOCTYPE html>
<!-- saved from url=(0349)https://disqus.com/embed/comments/?base=default&f=kindasortainsightful&t_i=%2F2018%2F02%2F14%2Frl-hard.html&t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&s_o=default#version=4cca83b0da0691f931ef86061fb7db43 -->
<html lang="en" dir="ltr" class="js no-touch localstorage sessionstorage contenteditable use-opacity-transitions embed-refresh embed-refresh-v2" style="--publisher-color: rgb(42,122,226); --publisher-color-safe: rgb(42,122,226);"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Disqus Comments</title>

    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <style>
        .alert--warning {
            border-radius: 3px;
            padding: 10px 15px;
            margin-bottom: 10px;
            background-color: #FFE070;
            color: #A47703;
        }

        .alert--warning a,
        .alert--warning a:hover,
        .alert--warning strong {
            color: #A47703;
            font-weight: bold;
        }

        .alert--error p,
        .alert--warning p {
            margin-top: 5px;
            margin-bottom: 5px;
        }
        
        </style>
    
    <style>
        
        html {
            overflow: hidden;
        }
        

        #error {
            display: none;
        }

        .clearfix:after {
            content: "";
            display: block;
            height: 0;
            clear: both;
            visibility: hidden;
        }

        
    </style>

<script crossorigin="anonymous" id="bootstrap-script" data-app="lounge" src="./lounge.load.4cca83b0da0691f931ef86061fb7db43.js.download"></script><meta http-equiv="Content-Security-Policy" content="script-src https:;"><style>@font-face{font-family:icons;src:url(https://c.disquscdn.com/embedv2/latest/icons.woff2) format("woff2"),url(/assets/font/icons.woff) format("woff");font-weight:400;font-style:normal}._icon_1x9qx_7{display:inline-flex;align-items:center;justify-content:center}._icon_1x9qx_7:before{font-family:icons;content:var(--icon-content);speak:none;font-style:normal;font-weight:400;font-variant:normal;text-transform:none;line-height:1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}._success_16l9s_1,._info_16l9s_1,._warn_16l9s_1,._error_16l9s_1{display:flex;justify-content:space-between;padding:10px 14px;color:#fff;border-bottom:2px solid rgba(60,78,110,.18);font-size:13px}.dark ._success_16l9s_1,.dark ._info_16l9s_1,.dark ._warn_16l9s_1,.dark ._error_16l9s_1{border-bottom:2px solid rgba(255,255,255,.2)}._success_16l9s_1 a,._info_16l9s_1 a,._warn_16l9s_1 a,._error_16l9s_1 a{font-weight:700;text-decoration:underline}._error_16l9s_1,._warn_16l9s_1{background:#f05f70}._info_16l9s_1,._success_16l9s_1{background:rgb(46,159,255)}._message_16l9s_33{display:flex;align-items:center}._icon_16l9s_38{margin-right:.5em;width:13px;height:13px}._dismiss_16l9s_44{background:transparent;border:none;cursor:pointer;color:inherit;font-size:16px}._icon_rsxid_1{font-size:16px;color:#ffd34f}._avatar-square_st8h3_1,._avatar-rounded_st8h3_1,._avatar-circle_st8h3_1{font-size:36px;position:relative;display:flex;align-items:center;justify-content:center;overflow:hidden;padding:0}._inner_st8h3_11{font-style:normal;font-weight:600;flex:auto;display:flex;align-items:center;justify-content:center;width:100%;height:100%;line-height:1.2;color:#fff;background:var(--publisher-color, rgb(46, 159, 255))}._image_st8h3_25{width:100%;height:100%;border-radius:inherit}._avatar-circle_st8h3_1{border-radius:50%}._avatar-rounded_st8h3_1{border-radius:16px}._avatar-square_st8h3_1{border-radius:2px}._avatar-large_st8h3_43{width:52px;height:52px}._avatar-medium_st8h3_48{width:40px;height:40px}._avatar-small_st8h3_53{width:36px;height:36px}._avatar-xsmall_st8h3_58{font-size:16px;width:30px;height:30px}._link_1hoja_1{color:var(--publisher-color, rgb(46, 159, 255))}._button_8fv5d_1{font-size:12px;font-weight:700;font-family:inherit;display:inline-block;padding:8px 12px;line-height:normal;border:initial;border-radius:3px;transition:all .25s ease-in-out;cursor:pointer;color:inherit}._button-fill_8fv5d_15{border-color:#687a86;background-color:#687a86;color:#fff}@media (hover: hover){._button-fill_8fv5d_15:hover{border-color:#526069;background-color:#526069;color:#fff}._button-fill_8fv5d_15:disabled,._button-fill_8fv5d_15:disabled:hover{cursor:default;border-color:#bcc5cb;background:#bcc5cb}.dark ._button-fill_8fv5d_15:disabled,.dark ._button-fill_8fv5d_15:disabled:hover{border-color:#ffffff80;background:rgba(255,255,255,.5);color:#ffffffb3}}._button-primary_8fv5d_38{border-color:#2e9fff;background-color:#2e9fff;color:#fff}@media (hover: hover){._button-primary_8fv5d_38:hover{border-color:#0087fa;background-color:#0087fa;color:#fff}._button-primary_8fv5d_38:disabled,._button-primary_8fv5d_38:disabled:hover{cursor:default;border-color:#c7e5ff;background:#c7e5ff}.dark ._button-primary_8fv5d_38:disabled,.dark ._button-primary_8fv5d_38:disabled:hover{border-color:#ffffff80;background:rgba(255,255,255,.5);color:#ffffffb3}}._button-danger_8fv5d_61{border-color:#f05f70;background-color:#f05f70;color:#fff}@media (hover: hover){._button-danger_8fv5d_61:hover{border-color:#ec3046;background-color:#ec3046;color:#fff}._button-danger_8fv5d_61:disabled,._button-danger_8fv5d_61:disabled:hover{cursor:default;border-color:#fdebed;background:#fdebed}.dark ._button-danger_8fv5d_61:disabled,.dark ._button-danger_8fv5d_61:disabled:hover{border-color:#ffffff80;background:rgba(255,255,255,.5);color:#ffffffb3}}._button-success_8fv5d_84{border-color:#5cb767;background-color:#5cb767;color:#fff}@media (hover: hover){._button-success_8fv5d_84:hover{border-color:#459b4f;background-color:#459b4f;color:#fff}._button-success_8fv5d_84:disabled,._button-success_8fv5d_84:disabled:hover{cursor:default;border-color:#c6e6ca;background:#c6e6ca}.dark ._button-success_8fv5d_84:disabled,.dark ._button-success_8fv5d_84:disabled:hover{border-color:#ffffff80;background:rgba(255,255,255,.5);color:#ffffffb3}}._card_hu9ay_1{overflow:hidden;color:#494e58;border:1px solid rgb(194,198,204);border-radius:5px;transition:all .25s ease-in-out}.dark ._card_hu9ay_1{color:#ffffffd9;border-color:#fff3}._content_zxk21_1{padding:12px 18px}._header_1iy7u_1{padding:10px 12px;border-bottom:1px solid rgb(235,238,242)}.dark ._header_1iy7u_1{border-color:#fff3}._heading_1iy7u_9{font-size:14px;font-weight:500;margin:0}._footer_pq6g3_1{display:flex;gap:10px;margin:0;padding:10px 18px 12px;border-top:1px solid rgb(235,238,242)}.dark ._footer_pq6g3_1{border-color:#fff3}._checkbox_1nula_1{display:inline-flex;align-items:center;gap:6px;line-height:1.3}._input_1nula_8{margin:0}._link_7oyne_1{color:inherit}._icon_1rgg8_1{margin-right:4px}._domain_1rgg8_5{font-size:11px;color:#656c7a}._loader_e4dlg_1{width:100%;height:var(--loader-height);text-align:center;background:url(data:image/gif;base64,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) no-repeat center center}._root_169ev_1{position:relative}._iframe_169ev_5{display:block;opacity:1;transition:opacity .5s ease-in-out}._iframe-loading_169ev_11{position:absolute;opacity:0;visibility:hidden}._image_1mcab_1{display:block;max-width:100%;max-height:480px;border-radius:3px}._root_1wfe0_1{position:relative;width:-webkit-max-content;width:-moz-max-content;width:max-content;max-width:100%}._container_1r7qu_1{min-height:100px}._mention_1xkh2_1{font-weight:700}._mention_1xkh2_1:before{content:"@"}.dark ._mention_1xkh2_1:before{color:#fff}._menu_1hdnv_1{border:2px solid #687a86;border-radius:15px 3px 15px 15px;background:#fff;outline:none}._button_1hdnv_8{display:inline-flex;align-items:center;justify-content:center;padding:0;color:#494e58;border:none;background:transparent;outline:none;cursor:pointer}._button_1hdnv_8:hover,._button_1hdnv_8[aria-expanded=true]{color:var(--publisher-color, rgb(46, 159, 255))}._item_2hnsa_1{font-size:11px;font-family:inherit;display:flex;padding:6px 8px;width:100%;color:#687a86;border:none;background:transparent;outline:none;cursor:pointer}._item_2hnsa_1:hover:not(:disabled),._item_2hnsa_1:focus:not(:disabled){color:var(--publisher-color, rgb(46, 159, 255))}._radio_1lyat_1{display:inline-flex;align-items:center;gap:6px;line-height:1.3}._input_1lyat_8{margin:0}._stars-inactive_1axb3_1,._stars-active_1axb3_1{display:flex;font-size:14px}._star-inactive_1axb3_6,._star-active_1axb3_6{font-size:14px}._root_1axb3_10{line-height:20px;display:inline-block;unicode-bidi:bidi-override;direction:ltr;position:relative}._stars-active_1axb3_1{position:absolute;z-index:1;top:0;left:0;width:var(--active-width);overflow:hidden;white-space:nowrap}._stars-inactive_1axb3_1{z-index:0}._star-active_1axb3_6{color:#ffd34f}._star-inactive_1axb3_6{color:#ebeef2}._spacer_1fr9r_1{display:inline-block;width:var(--spacer-width)}._spoiler_1mxys_1{display:inline;background:rgb(127,145,158);color:transparent;padding:0 .5em}._spoiler_1mxys_1 a{visibility:hidden;transition:none}._spoiler_1mxys_1:hover,._spoiler_1mxys_1:focus{background:rgb(231,233,238);color:inherit}._spoiler_1mxys_1:hover a,._spoiler_1mxys_1:focus a{visibility:visible}.dark ._spoiler_1mxys_1:hover,.dark ._spoiler_1mxys_1:focus{background:rgba(255,255,255,.08)}._popover_1ocis_1{z-index:1000}._button_rdrky_1{border:none;background:transparent;padding:0;margin:0}._tooltip_ia50n_1{position:relative;padding:8px;text-align:center;overflow:auto;background:#fff;border-radius:4px;box-shadow:0 0 0 3px #0003;color:#7f919e}._tooltip_ia50n_1{width:300px}._text_ia50n_16{font-size:14px;line-height:1.4;margin:0 0 12px}._tabs_1wiw0_1{display:flex;align-items:stretch}._disabled_1sb5m_1,._selected_1sb5m_1,._tab_1sb5m_1{font-size:12px;display:block;width:100%;padding:10px 18px 10px 10px;overflow:visible;white-space:normal;background:rgba(0,0,0,.03);border:1px solid rgb(235,238,242);border-width:0 1px 1px 0;transition:all .2s ease-in-out;margin-bottom:0;color:#687a86}._disabled_1sb5m_1 input[type=radio],._selected_1sb5m_1 input[type=radio],._tab_1sb5m_1 input[type=radio]{display:none}._disabled_1sb5m_1:first-of-type,._selected_1sb5m_1:first-of-type,._tab_1sb5m_1:first-of-type{border-left:none}._disabled_1sb5m_1:last-of-type,._selected_1sb5m_1:last-of-type,._tab_1sb5m_1:last-of-type{border-right:none}.dark ._disabled_1sb5m_1,.dark ._selected_1sb5m_1,.dark ._tab_1sb5m_1{border-color:#fff3}._tab_1sb5m_1{cursor:pointer}._tab_1sb5m_1:hover{background:rgba(0,0,0,.08)}.dark ._tab_1sb5m_1{color:#fff9;background:rgba(255,255,255,.08)}._selected_1sb5m_1{font-weight:600;color:var(--publisher-color, rgb(46, 159, 255));background:transparent;border-bottom:none}.dark ._selected_1sb5m_1{color:#ffffffd9}._disabled_1sb5m_1{color:#c2c6cc}.dark ._disabled_1sb5m_1{color:#ffffff59;background:rgba(255,255,255,.08)}._text_1sb5m_57{font-size:14px;font-weight:500;display:flex;align-items:center;gap:5px;justify-content:center;margin-bottom:2px;text-align:center}._selected_ln985_1,._selectable_ln985_1{position:relative}._selected_ln985_1:before,._selectable_ln985_1:before{content:"";display:block;position:absolute;top:-2px;left:-2px;width:calc(100% + 4px);height:calc(100% + 4px);opacity:0;box-shadow:0 0 0 1px #3c4e6e2e;border-radius:4px;transition:opacity ease-in-out .25s}.dark ._selected_ln985_1:before,.dark ._selectable_ln985_1:before{box-shadow:0 0 0 1px #fff3}._selectable_ln985_1:hover:before{opacity:.75}._selected_ln985_1:before{opacity:1}._delete_ln985_29{display:block;position:absolute;top:-18px;right:-18px;width:32px;height:32px;padding:6px;color:#fff;background:var(--publisher-color, rgb(46, 159, 255));cursor:pointer;border-radius:50%;box-shadow:0 2px 8px #0003}.light-anchor ._delete_ln985_29{color:#656c7a}._element_ln985_47{display:inline-block;background:inherit}._element_ln985_47:not(:first-child){margin-top:8px}._image_ln985_55{display:block;max-width:100%;max-height:20em;box-shadow:none;border-radius:3px}._wrapper_ln985_63{position:relative;display:block;background:inherit;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content}._loader_ln985_70{display:block;height:115px;background:rgba(16,48,68,.03);width:150px;border-radius:16px}._dialog_1p5t1_1{background:white;border:2px solid rgba(60,78,110,.18);border-radius:16px}.dark ._dialog_1p5t1_1{background:rgb(42,46,46);border:2px solid rgba(255,255,255,.2)}._submit_1p5t1_11,._cancel_1p5t1_11{border-radius:16px}._form_1p5t1_15{font-size:14px;display:flex;flex-direction:column;gap:8px}._field_1p5t1_22{display:flex;align-items:center;gap:8px}._label_1p5t1_28{color:#7f919e}.dark ._label_1p5t1_28{color:#eee}._input_1p5t1_35{font-size:100%;font-family:inherit;display:block;width:100%;margin:0;padding:4px 6px;white-space:normal;border-radius:4px;border:1px solid rgba(60,78,110,.18);box-sizing:border-box;background:transparent}._input_1p5t1_35:disabled{color:#7f919e}._input_1p5t1_35:focus{border-color:var(--publisher-color, rgb(46, 159, 255));outline:none}._input_1p5t1_35::-webkit-input-placeholder{font-size:13px;color:#7f919e}._input_1p5t1_35::-moz-placeholder{font-size:13px;color:#7f919e}._input_1p5t1_35:-ms-input-placeholder{font-size:13px;color:#7f919e}._input_1p5t1_35::placeholder{font-size:13px;color:#7f919e}.dark ._input_1p5t1_35{color:#eee;border-color:#fff3}.dark ._input_1p5t1_35::-webkit-input-placeholder{color:#ffffff80}.dark ._input_1p5t1_35::-moz-placeholder{color:#ffffff80}.dark ._input_1p5t1_35:-ms-input-placeholder{color:#ffffff80}.dark ._input_1p5t1_35::placeholder{color:#ffffff80}.dark ._input_1p5t1_35:focus{border-color:var(--publisher-color, rgb(46, 159, 255))}._dialog_1p5t1_1{width:300px;padding:16px;border-width:1px;box-shadow:0 4px 8px -1px #0000001a}.dark ._dialog_1p5t1_1{border-width:1px}._buttons_1p5t1_80{display:flex;width:100%;align-items:center;justify-content:flex-end;gap:8px}._cancel_1p5t1_11{background:none;box-shadow:0 0 0 1px #c2c6cc;color:#7f919e}._cancel_1p5t1_11:hover{color:#7f919e;background:rgb(231,233,238)}.dark ._cancel_1p5t1_11{color:#eee;box-shadow:0 0 0 1px #fff3}.dark ._cancel_1p5t1_11:hover{background:rgb(73,78,88)}._selected_10kig_1,._selectable_10kig_1{position:relative}._selected_10kig_1:before,._selectable_10kig_1:before{content:"";display:block;position:absolute;top:-2px;left:-2px;width:calc(100% + 4px);height:calc(100% + 4px);opacity:0;box-shadow:0 0 0 1px #3c4e6e2e;border-radius:4px;transition:opacity ease-in-out .25s}.dark ._selected_10kig_1:before,.dark ._selectable_10kig_1:before{box-shadow:0 0 0 1px #fff3}._selectable_10kig_1:hover:before{opacity:.75}._selected_10kig_1:before{opacity:1}._delete_10kig_29{display:block;position:absolute;top:-18px;right:-18px;width:32px;height:32px;padding:6px;color:#fff;background:var(--publisher-color, rgb(46, 159, 255));cursor:pointer;border-radius:50%;box-shadow:0 2px 8px #0003}.light-anchor ._delete_10kig_29{color:#656c7a}._preview_10kig_47{display:block;position:relative;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content;min-width:300px;max-width:100%;border-radius:3px}._no-pointer_10kig_56{display:block;overflow:hidden;pointer-events:none;border-radius:3px}._button_1ka0a_1,._button_1ka0a_1:active,._button_1ka0a_1:hover{flex:0 0 auto;background:none;padding:0;border:none;cursor:pointer;margin:0;width:24px;height:24px;display:flex;align-items:center;justify-content:center;color:#7f919e;opacity:.6;border-radius:4px}._button_1ka0a_1:hover{opacity:1}._button_1ka0a_1:disabled{opacity:.25;cursor:default}.dark ._button_1ka0a_1{color:#ffffff80}._button_1ka0a_1:active,._button_1ka0a_1:hover{opacity:1;background:rgba(60,75,120,.12)}.dark ._button_1ka0a_1:active,.dark ._button_1ka0a_1:hover{background:rgba(255,255,255,.2)}._container_1ka0a_36{font-size:14px;display:flex;align-items:center;gap:8px;position:relative;overflow-y:auto;max-height:400px;max-width:90vw;padding:5px 12px;border:1px solid rgb(231,233,238);border-radius:16px;background:#fff;box-shadow:0 4px 8px -1px #0000001a}.dark ._container_1ka0a_36{border:1px solid rgba(255,255,255,.2);background:rgb(42,46,46)}._link_1ka0a_56{color:var(--publisher-color, rgb(46, 159, 255));max-width:300px;overflow:hidden;white-space:nowrap;text-overflow:ellipsis;outline:none}._button_1ka0a_1{font-size:14px;opacity:1}._separator_1ka0a_69{display:inline-block;width:1px;height:18px;background:rgb(194,198,204)}.dark ._separator_1ka0a_69{background:rgba(255,255,255,.35)}._icon_1ka0a_79{width:16px;height:16px}._block_865k6_1{display:block;max-width:-webkit-max-content;max-width:-moz-max-content;max-width:max-content}._selected_12oyo_1,._mention_12oyo_1{font-weight:700;position:relative}._selected_12oyo_1:before,._mention_12oyo_1:before{content:"@"}._selected_12oyo_1{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border-radius:2px;background:rgba(60,78,110,.18);box-shadow:0 0 0 2px #3c4e6e2e}.dark ._selected_12oyo_1{box-shadow:0 0 0 2px #fff3;background:rgba(255,255,255,.2)}._default_1alzx_1{background:rgb(127,145,158);color:transparent}._default_1alzx_1 a,._default_1alzx_1 img,._default_1alzx_1 video{visibility:hidden}.dark ._default_1alzx_1{background:rgba(255,255,255,.5)}._active_1alzx_12,._default_1alzx_1:hover{background:rgb(231,233,238);color:inherit}._active_1alzx_12 a,._default_1alzx_1:hover a,._active_1alzx_12 img,._default_1alzx_1:hover img,._active_1alzx_12 video,._default_1alzx_1:hover video{visibility:visible}.dark ._active_1alzx_12,.dark ._default_1alzx_1:hover{background:rgba(255,255,255,.2)}._selected_4roo0_1,._selectable_4roo0_1{position:relative}._selected_4roo0_1:before,._selectable_4roo0_1:before{content:"";display:block;position:absolute;top:-2px;left:-2px;width:calc(100% + 4px);height:calc(100% + 4px);opacity:0;box-shadow:0 0 0 1px #3c4e6e2e;border-radius:4px;transition:opacity ease-in-out .25s}.dark ._selected_4roo0_1:before,.dark ._selectable_4roo0_1:before{box-shadow:0 0 0 1px #fff3}._selectable_4roo0_1:hover:before{opacity:.75}._selected_4roo0_1:before{opacity:1}._delete_4roo0_29{display:block;position:absolute;top:-18px;right:-18px;width:32px;height:32px;padding:6px;color:#fff;background:var(--publisher-color, rgb(46, 159, 255));cursor:pointer;border-radius:50%;box-shadow:0 2px 8px #0003}.light-anchor ._delete_4roo0_29{color:#656c7a}._video_4roo0_47{display:block;position:relative;max-width:100%;max-height:20em;box-shadow:none;border-radius:3px;pointer-events:none}._container_4roo0_57{display:inline-block;position:relative;background:inherit}._wrapper_4roo0_63{position:relative;display:block;background:inherit;width:-webkit-fit-content;width:-moz-fit-content;width:fit-content}._quote_11ucn_1{margin:8px 0 0;padding:0 0 0 12px;border-left:4px solid #687a86}._quote_11ucn_1:first-child{margin-top:0}._code_vr1vh_1{font-family:monospace}._button_1559b_1,._active_1559b_1{flex:0 0 auto;background:none;padding:0;border:none;cursor:pointer;margin:0;width:24px;height:24px;display:flex;align-items:center;justify-content:center;color:#7f919e;opacity:.6;border-radius:4px}._button_1559b_1:hover,._active_1559b_1:hover{opacity:1}._button_1559b_1:disabled,._active_1559b_1:disabled{opacity:.25;cursor:default}.dark ._button_1559b_1,.dark ._active_1559b_1{color:#ffffff80}._active_1559b_1{opacity:1;background:rgba(60,75,120,.12)}.dark ._active_1559b_1{background:rgba(255,255,255,.2)}._icon_1559b_36{width:16px;height:16px}._button_12m5a_1{flex:0 0 auto;background:none;padding:0;border:none;cursor:pointer;margin:0;width:24px;height:24px;display:flex;align-items:center;justify-content:center;color:#7f919e;opacity:.6;border-radius:4px}._button_12m5a_1:hover{opacity:1}._button_12m5a_1:disabled{opacity:.25;cursor:default}.dark ._button_12m5a_1{color:#ffffff80}._categories_lunsx_1{display:flex;flex-direction:column;gap:2px;max-height:400px;padding:4px 10px;overflow-y:scroll}@media only screen and (min-width: 481px){._categories_lunsx_1{flex-direction:row;max-height:800px}}._column_lunsx_16{display:flex;flex-direction:column;gap:2px}._image_lunsx_22{display:flex;align-items:center;justify-content:center;position:relative;cursor:pointer;border:2px solid white;background:rgb(235,238,242)}._image_lunsx_22:hover{border-color:#2e87e7;border-radius:2px}._image_lunsx_22:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;opacity:.6;background:#2a2e2e}.dark ._image_lunsx_22{background:rgba(255,255,255,.2);border-color:#2a2e2e}.dark ._image_lunsx_22:hover{border-color:#2e87e7}._title_lunsx_54{display:flex;align-items:center;justify-content:center;position:absolute;top:0;left:0;width:100%;height:100%;color:#fff;text-shadow:1px 1px #2a2e2e;text-align:center}._gifs_lkt4v_1{max-height:400px;padding:4px 10px;overflow-y:scroll}@media only screen and (min-width: 481px){._gifs_lkt4v_1{max-height:800px}}._columns_lkt4v_12{display:flex;flex-direction:column;gap:2px}@media only screen and (min-width: 481px){._columns_lkt4v_12{flex-direction:row}}._column_lkt4v_12{display:flex;flex-direction:column;gap:2px}._image_lkt4v_29{display:flex;align-items:center;justify-content:center;position:relative;max-width:100%;cursor:pointer;border:2px solid white;background:rgb(235,238,242)}._image_lkt4v_29:hover{border-color:#2e9fff;border-radius:2px}.dark ._image_lkt4v_29{background:rgba(255,255,255,.2);border-color:#2a2e2e}.dark ._image_lkt4v_29:hover{border-color:#2e87e7}._searchbox_1ftd7_1{box-sizing:border-box;padding:12px 10px 8px}._input_1ftd7_6{font-size:100%;font-family:inherit;display:block;width:100%;min-height:28px;height:auto;margin:0;padding:2px 6px;white-space:normal;border-radius:4px;border:2px solid rgba(60,78,110,.18);box-sizing:border-box;outline:none}.dark ._input_1ftd7_6{color:#eee;border-color:#ffffff80;background:transparent}@-webkit-keyframes _pulse_drbub_1{0%{opacity:.5}50%{opacity:1}to{opacity:.5}}@keyframes _pulse_drbub_1{0%{opacity:.5}50%{opacity:1}to{opacity:.5}}._skeleton_drbub_12{display:flex;flex-direction:column;gap:6px;padding:4px 12px;max-height:400px;overflow:hidden}@media only screen and (min-width: 481px){._skeleton_drbub_12{flex-direction:row;max-height:800px}}._image_drbub_27{background:rgb(235,238,242);-webkit-animation:_pulse_drbub_1 2s ease-in-out infinite;animation:_pulse_drbub_1 2s ease-in-out infinite}.dark ._image_drbub_27{background:rgba(255,255,255,.2)}._column_drbub_35{display:flex;flex-direction:column;gap:6px}._root_4nri8_1{position:relative}._popout_4nri8_5{display:flex;flex-direction:column;justify-content:space-between;align-items:center;background:white;border-radius:4px;border:2px solid rgba(60,78,110,.18)}.dark ._popout_4nri8_5{border-color:#fff3;background:rgb(42,46,46)}._searchbox_4nri8_19{width:100%}._powered-by_4nri8_23{width:100px;margin:4px 12px;color:#748793}.dark ._powered-by_4nri8_23{color:#ffffff59}._zone_1xgo0_1{border-radius:16px;position:absolute;inset:0;background-color:#0006;z-index:1;display:flex;align-items:center;justify-content:center}._wrapper_1xgo0_12{border:3px dashed #fff;padding:12px;width:90%;text-align:center;border-radius:6px}._text_1xgo0_20{color:#fff;font-size:15px;font-weight:700;font-style:normal}._placeholder_s9avi_1{font-style:normal;font-weight:400;position:absolute;top:20px;left:20px;color:#000;opacity:.33;line-height:1.4}.dark ._placeholder_s9avi_1{color:#fff}._separator_p7fwl_1{display:inline-block;width:2px;height:24px;margin:0 2px;background:rgba(60,78,110,.18)}.dark ._separator_p7fwl_1{background:rgba(255,255,255,.08)}._expand_k0g7a_1,._expand-active_k0g7a_1{flex:0 0 auto;background:none;padding:0;border:none;cursor:pointer;margin:0;width:24px;height:24px;display:flex;align-items:center;justify-content:center;color:#7f919e;opacity:.6;border-radius:4px}._expand_k0g7a_1:hover,._expand-active_k0g7a_1:hover{opacity:1}._expand_k0g7a_1:disabled,._expand-active_k0g7a_1:disabled{opacity:.25;cursor:default}.dark ._expand_k0g7a_1,.dark ._expand-active_k0g7a_1{color:#ffffff80}._expand-active_k0g7a_1{opacity:1;background:rgba(60,75,120,.12)}.dark ._expand-active_k0g7a_1{background:rgba(255,255,255,.2)}._expand-active_k0g7a_1,._expand_k0g7a_1{width:16px;height:16px}._menu_k0g7a_41{display:inline-flex;align-items:center;gap:4px}._toolbar_k0g7a_47{padding:5px 6px}._toolbar-primary_k0g7a_51{display:flex;justify-content:space-between}._toolbar-secondary-multirow_k0g7a_56,._toolbar-secondary_k0g7a_56{display:grid;grid-auto-flow:column;gap:6px;margin-top:6px}._toolbar-secondary-multirow_k0g7a_56{grid-template-rows:repeat(2,auto)}._expand_k0g7a_1{font-size:14px}._expand_k0g7a_1:hover{opacity:.6}._expand-active_k0g7a_1{background:none}._actions_k0g7a_78{display:inline-flex;gap:12px;margin-right:-5px}._submit_k0g7a_84{font-size:15px;font-style:normal;font-weight:700;position:relative;line-height:1;height:-webkit-fit-content;height:-moz-fit-content;height:fit-content;padding:7px 15px;border:none;text-shadow:none;white-space:nowrap;border-radius:14px;color:#fff;background-color:var(--publisher-color, rgb(46, 159, 255))}.light-anchor ._submit_k0g7a_84{color:#656c7a}._submit_k0g7a_84:before{content:"";display:block;position:absolute;top:0;left:0;width:100%;height:100%;background:rgba(0,0,0,.1);border-radius:14px;opacity:0;transition:all .25s ease-in-out}._submit_k0g7a_84:hover{background-color:var(--publisher-color, rgb(46, 159, 255))}._submit_k0g7a_84:hover:before{opacity:1}._submit-text_k0g7a_122{position:relative}._cancel_k0g7a_126{padding:7px;background-color:transparent;border:none;color:var(--publisher-color, rgb(46, 159, 255));cursor:pointer;font-weight:700;font-size:15px;line-height:1}._cancel_k0g7a_126:hover{color:#656c7a}._button_1wqlf_1{flex:0 0 auto;background:none;padding:0;border:none;cursor:pointer;margin:0;width:24px;height:24px;display:flex;align-items:center;justify-content:center;color:#7f919e;opacity:.6;border-radius:4px}._button_1wqlf_1:hover{opacity:1}._button_1wqlf_1:disabled{opacity:.25;cursor:default}.dark ._button_1wqlf_1{color:#ffffff80}._icon_1wqlf_28{width:16px;height:16px}._container_if5tp_1{background:white;border:2px solid rgba(60,78,110,.18);border-radius:16px}.dark ._container_if5tp_1{background:rgb(42,46,46);border:2px solid rgba(255,255,255,.2)}._item-active_if5tp_11,._item_if5tp_11{font-weight:500;display:flex;gap:16px;position:relative;padding:8px;overflow:hidden;cursor:pointer;color:#7f919e}.dark ._item-active_if5tp_11,.dark ._item_if5tp_11{color:#ffffff80}._container_if5tp_1{width:100%;max-height:200px;padding:0;overflow-y:scroll;border-radius:0 0 3px 3px}._header_if5tp_33{font-size:11px;font-weight:700;text-transform:uppercase;line-height:11px;margin:0;padding:8px;color:#7f919e;border:0}.dark ._header_if5tp_33{color:#ffffff80}._list_if5tp_47{margin:0;padding:0;list-style:none}._item_if5tp_11{background:transparent}._item_if5tp_11:hover{background:rgb(247,249,250)}.dark ._item_if5tp_11:hover{background:rgba(255,255,255,.08)}._item-active_if5tp_11{background:rgb(46,159,255);color:#fff}.dark ._item-active_if5tp_11{color:#fff}._avatar_if5tp_71{flex:0 0 auto;width:22px;height:22px}._overlay_1i4qh_1{z-index:1000}._container_ylcfx_1{position:relative;background:#fff;border:2px solid rgba(60,78,110,.18);border-radius:16px;line-height:1.4}.dark ._container_ylcfx_1{background:rgba(255,255,255,.05);border:2px solid rgba(255,255,255,.2)}._editor-expanded_ylcfx_13,._editor_ylcfx_13{position:relative;overflow-y:auto;max-height:350px;min-height:65px!important;padding:20px;transition:all .15s ease-in-out;outline:none;color:#2a2e2e;word-break:break-word}._editor-expanded_ylcfx_13 p,._editor_ylcfx_13 p{margin:8px 0 0}._editor-expanded_ylcfx_13 p:first-child,._editor_ylcfx_13 p:first-child{margin-top:0}._editor-expanded_ylcfx_13 a:link,._editor_ylcfx_13 a:link,._editor-expanded_ylcfx_13 a:visited,._editor_ylcfx_13 a:visited{color:var(--publisher-color, rgb(46, 159, 255))}.dark ._editor-expanded_ylcfx_13,.dark ._editor_ylcfx_13{color:#eee}._editor-container-expanded_ylcfx_37,._editor-container_ylcfx_37{overflow:hidden;border-radius:16px}._editor-container-expanded_ylcfx_37{border-radius:16px 16px 0 0}._editor-expanded_ylcfx_13{border-bottom:2px solid rgba(60,78,110,.18);border-radius:16px 16px 0 0;min-height:115px!important}.dark ._editor-expanded_ylcfx_13{border-bottom:2px solid rgba(255,255,255,.2)}._placeholder-submit-button_ylcfx_55{display:none}
</style><link rel="stylesheet" href="./lounge.afe5231d53e8a6cd708e90b2932e99dc.css"><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="lounge/main" src="./lounge.bundle.af134f6a9c289b5cf867d1c96d050b4c.js.download"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="remote/config" src="./config.js.download"></script><style id="css_1722275193242"></style><!--<base target="_parent">--><base href="." target="_parent"><style type="text/css">@import url("https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,400;0,500;0,600;0,700;1,400;1,700&display=swap"); body.roboto , body.roboto input, body.roboto select, body.roboto textarea { font-family: Roboto, sans-serif; }</style></head>
<body class="roboto dark-anchor">
    

    
    <div id="error" class="alert--error">
        <p>We were unable to load Disqus. If you are a moderator please see our <a href="https://docs.disqus.com/help/83/"> troubleshooting guide</a>. </p>
    </div>

    
    <script type="text/json" id="disqus-forumData">{"session":{"canModerate":false,"audienceSyncVerified":false,"canReply":true,"mustVerify":false,"recaptchaPublicKey":"6Lfx6u0SAAAAAI1QkeTW397iQv1MsBfbDaYlwxK_","mustVerifyEmail":false},"forum":{"aetBannerConfirmation":null,"founder":"184457898","twitterName":null,"commentsLinkOne":"1 Comment","guidelines":null,"favicon":{"permalink":"https://disqus.com/api/forums/favicons/kindasortainsightful.jpg","cache":"//a.disquscdn.com/1721054975/images/favicon-default.png"},"commentsLinkZero":"0 Comments","disableDisqusBranding":false,"id":"kindasortainsightful","createdAt":"2015-11-26T15:47:41.337902","category":null,"aetBannerEnabled":false,"aetBannerTitle":null,"raw_guidelines":null,"initialCommentCount":null,"votingType":null,"daysUnapproveNewUsers":null,"installCompleted":true,"moderatorBadgeText":"","commentPolicyText":null,"aetEnabled":false,"channel":null,"sort":4,"description":"\u003cp>Opinions by a dude on the internet\u003c/p>","newPolicy":true,"raw_description":"Opinions by a dude on the internet","customFont":null,"language":"en","adsReviewStatus":1,"commentsPlaceholderTextEmpty":null,"daysAlive":0,"forumCategory":null,"linkColor":null,"colorScheme":"auto","pk":"3902136","commentsPlaceholderTextPopulated":null,"permissions":{},"commentPolicyLink":null,"aetBannerDescription":null,"name":"Sorta Insightful","commentsLinkMultiple":"{num} Comments","settings":{"threadRatingsEnabled":false,"adsDRNativeEnabled":false,"behindClickEnabled":false,"disable3rdPartyTrackers":false,"adsVideoEnabled":false,"adsProductVideoEnabled":false,"adsPositionTopEnabled":false,"ssoRequired":false,"unapproveLinks":false,"adsPositionRecommendationsEnabled":false,"linkAffiliationEnabled":true,"adsProductLinksThumbnailsEnabled":false,"hasCustomAvatar":false,"organicDiscoveryEnabled":true,"adsProductDisplayEnabled":false,"adsProductLinksEnabled":false,"audienceSyncEnabled":false,"threadReactionsEnabled":false,"adsEnabled":false,"disableSocialShare":false,"allowAnonPost":false,"adsProductStoriesEnabled":false,"sidebarEnabled":false,"adultContent":false,"allowAnonVotes":false,"gifPickerEnabled":true,"mustVerify":true,"badgesEnabled":false,"mustVerifyEmail":true,"unapproveNewUsersEnabled":false,"mediaembedEnabled":true,"userIdentityDisabled":false,"adsPositionBottomEnabled":false,"discoveryLocked":false,"validateAllPosts":false,"adsSettingsLocked":false,"isVIP":false,"adsPositionInthreadEnabled":false},"organizationId":2819052,"typeface":"auto","url":"http://www.alexirpan.com","daysThreadAlive":0,"avatar":{"small":{"permalink":"https://disqus.com/api/forums/avatars/kindasortainsightful.jpg?size=32","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"large":{"permalink":"https://disqus.com/api/forums/avatars/kindasortainsightful.jpg?size=92","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"}},"signedUrl":"http://disq.us/?url=http%3A%2F%2Fwww.alexirpan.com&key=FFTlwG5m5TDm5Doy7ZF5Sw"}}</script>

    <script type="text/json" id="disqus-threadData">{"cursor":{"hasPrev":false,"prev":null,"total":68,"hasNext":true,"next":"1:0:0"},"code":0,"response":{"lastModified":1720583685,"posts":[{"editableUntil":"2018-02-21T19:37:07","dislikes":0,"thread":"6479477416","numReports":0,"likes":8,"message":"\u003cp>that \"cheetah\" running on its back went pretty darn fast though. Was it actually slower? It seems like the solution would be to add a high cost for hitting the head/back. That's why real cheetas don't run like that.\u003c/p>","id":"3758231210","createdAt":"2018-02-14T19:37:07","author":{"username":"arvash","about":"","name":"arvash","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2009-06-13T06:24:25","profileUrl":"https://disqus.com/by/arvash/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"382251","avatar":{"permalink":"https://disqus.com/api/users/avatars/arvash.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/arvash.jpg","cache":"https://c.disquscdn.com/uploads/users/38/2251/avatar128.jpg?1368285631"},"cache":"https://c.disquscdn.com/uploads/users/38/2251/avatar92.jpg?1368285631","large":{"permalink":"https://disqus.com/api/users/avatars/arvash.jpg","cache":"https://c.disquscdn.com/uploads/users/38/2251/avatar92.jpg?1368285631"},"small":{"permalink":"https://disqus.com/api/users/avatars/arvash.jpg","cache":"https://c.disquscdn.com/uploads/users/38/2251/avatar32.jpg?1368285631"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"that \"cheetah\" running on its back went pretty darn fast though. Was it actually slower? It seems like the solution would be to add a high cost for hitting the head/back. That's why real cheetas don't run like that.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":8,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2018-02-25T02:38:06","dislikes":0,"thread":"6479477416","numReports":0,"likes":9,"message":"\u003cp>It moves at about 35% of the speed of the cheetah that runs right side up.\u003c/p>","id":"3763765584","createdAt":"2018-02-18T02:38:06","author":{"username":"alexirpan","about":"","name":"alexirpan","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-11-26T20:40:20","profileUrl":"https://disqus.com/by/alexirpan/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"184457898","avatar":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3758231210,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"It moves at about 35% of the speed of the cheetah that runs right side up.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":9,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-03-03T13:56:29","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>Solution, two model animals with some social learning. ;)\u003c/p>","id":"3774002236","createdAt":"2018-02-24T13:56:29","author":{"username":"paulmcgee","about":"","name":"Paul McGee","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-06-09T14:48:52","profileUrl":"https://disqus.com/by/paulmcgee/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"55671418","avatar":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar128.jpg?1370789333"},"cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar92.jpg?1370789333","large":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar92.jpg?1370789333"},"small":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar32.jpg?1370789333"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3763765584,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Solution, two model animals with some social learning. ;)","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":2,"points":1,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-11-16T21:49:07","dislikes":1,"thread":"6479477416","numReports":0,"likes":9,"message":"\u003cp>BTW, I observed the \"running on the back\" behavior in real life. My daughter, when she was learning to crawl, found it easier to get to the toy by lying on her back, pushing with her legs, and occasionally stopping and tilting her head backwards to see whether she was getting closer to the toy. And she was getting quite good and quite fast at it. We actually had to turn her over and encourage her to crawl \"properly\". So this should be considered a valid solution :)\u003c/p>","id":"4187389914","createdAt":"2018-11-09T21:49:07","author":{"username":"robertioffe","about":"","name":"Robert Ioffe","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-02-17T22:29:33","profileUrl":"https://disqus.com/by/robertioffe/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"144914500","avatar":{"permalink":"https://disqus.com/api/users/avatars/robertioffe.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/robertioffe.jpg","cache":"https://c.disquscdn.com/uploads/users/14491/4500/avatar200.jpg?1639709419"},"cache":"https://c.disquscdn.com/uploads/users/14491/4500/avatar92.jpg?1639709419","large":{"permalink":"https://disqus.com/api/users/avatars/robertioffe.jpg","cache":"https://c.disquscdn.com/uploads/users/14491/4500/avatar92.jpg?1639709419"},"small":{"permalink":"https://disqus.com/api/users/avatars/robertioffe.jpg","cache":"https://c.disquscdn.com/uploads/users/14491/4500/avatar32.jpg?1639709419"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"BTW, I observed the \"running on the back\" behavior in real life. My daughter, when she was learning to crawl, found it easier to get to the toy by lying on her back, pushing with her legs, and occasionally stopping and tilting her head backwards to see whether she was getting closer to the toy. And she was getting quite good and quite fast at it. We actually had to turn her over and encourage her to crawl \"properly\". So this should be considered a valid solution :)","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":8,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2024-01-18T22:06:51","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>I heard it's not very common but some babies learn to do that\u003c/p>","id":"6364488128","createdAt":"2024-01-11T22:06:51","author":{"username":"erangerenrot","about":"","name":"Eran Gerenrot","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-10-06T10:12:39","profileUrl":"https://disqus.com/by/erangerenrot/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"177487292","avatar":{"permalink":"https://disqus.com/api/users/avatars/erangerenrot.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/erangerenrot.jpg","cache":"https://c.disquscdn.com/uploads/users/17748/7292/avatar200.jpg?1705010812"},"cache":"https://c.disquscdn.com/uploads/users/17748/7292/avatar92.jpg?1705010812","large":{"permalink":"https://disqus.com/api/users/avatars/erangerenrot.jpg","cache":"https://c.disquscdn.com/uploads/users/17748/7292/avatar92.jpg?1705010812"},"small":{"permalink":"https://disqus.com/api/users/avatars/erangerenrot.jpg","cache":"https://c.disquscdn.com/uploads/users/17748/7292/avatar32.jpg?1705010812"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":4187389914,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"I heard it's not very common but some babies learn to do that","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-02-22T16:46:35","dislikes":0,"thread":"6479477416","numReports":0,"likes":5,"message":"\u003cp>This is a great blog post! I think you've captured the sentiments of every grad student trying to get Deep RL to work.\u003c/p>\u003cp>One paper that I think might be useful to add to the ones you've linked to is Deep Q-learning from Demonstrations (\u003ca href=\"http://disq.us/url?url=http%3A%2F%2Fmlanctot.info%2Ffiles%2Fpapers%2Faaai18-dqfd.pdf%3A4O0b-D9aiAGcYZHtnlAbIPe5Y5s&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"http://mlanctot.info/files/papers/aaai18-dqfd.pdf\">http://mlanctot.info/files/...\u003c/a> ).\u003cbr>This paper incorporates human demonstrations into the training data of a DQN agent to accelerate learning.\u003c/p>\u003cp>Regardless, this is some necessary and good discussion.\u003c/p>","id":"3759654366","createdAt":"2018-02-15T16:46:35","author":{"username":"ishandurugkar","about":"","name":"Ishan Durugkar","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-02-15T16:36:27","profileUrl":"https://disqus.com/by/ishandurugkar/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"280205521","avatar":{"permalink":"https://disqus.com/api/users/avatars/ishandurugkar.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/ishandurugkar.jpg","cache":"https://c.disquscdn.com/uploads/users/28020/5521/avatar128.jpg?1518713197"},"cache":"https://c.disquscdn.com/uploads/users/28020/5521/avatar92.jpg?1518713197","large":{"permalink":"https://disqus.com/api/users/avatars/ishandurugkar.jpg","cache":"https://c.disquscdn.com/uploads/users/28020/5521/avatar92.jpg?1518713197"},"small":{"permalink":"https://disqus.com/api/users/avatars/ishandurugkar.jpg","cache":"https://c.disquscdn.com/uploads/users/28020/5521/avatar32.jpg?1518713197"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"This is a great blog post! I think you've captured the sentiments of every grad student trying to get Deep RL to work.\n\nOne paper that I think might be useful to add to the ones you've linked to is Deep Q-learning from Demonstrations (http://mlanctot.info/files/papers/aaai18-dqfd.pdf ).\nThis paper incorporates human demonstrations into the training data of a DQN agent to accelerate learning.\n\nRegardless, this is some necessary and good discussion.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":5,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-02-23T07:03:25","dislikes":0,"thread":"6479477416","numReports":0,"likes":4,"message":"\u003cp>Particularly love this piece:\u003cbr>\"...If your current policy explores too much you get junk data and learn nothing. Exploit too much and you burn-in behaviors that aren\u2019t optimal.\"\u003cbr>Might as well be an observation of real life xD\u003c/p>","id":"3760829947","createdAt":"2018-02-16T07:03:25","author":{"username":"jesuscastaneda","about":"","name":"jesuscastaneda","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-01-02T06:47:51","profileUrl":"https://disqus.com/by/jesuscastaneda/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"40076455","avatar":{"permalink":"https://disqus.com/api/users/avatars/jesuscastaneda.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/jesuscastaneda.jpg","cache":"https://c.disquscdn.com/uploads/users/4007/6455/avatar128.jpg?1518764606"},"cache":"https://c.disquscdn.com/uploads/users/4007/6455/avatar92.jpg?1518764606","large":{"permalink":"https://disqus.com/api/users/avatars/jesuscastaneda.jpg","cache":"https://c.disquscdn.com/uploads/users/4007/6455/avatar92.jpg?1518764606"},"small":{"permalink":"https://disqus.com/api/users/avatars/jesuscastaneda.jpg","cache":"https://c.disquscdn.com/uploads/users/4007/6455/avatar32.jpg?1518764606"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Particularly love this piece:\n\"...If your current policy explores too much you get junk data and learn nothing. Exploit too much and you burn-in behaviors that aren\u2019t optimal.\"\nMight as well be an observation of real life xD","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":4,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-04-19T08:01:18","dislikes":0,"thread":"6479477416","numReports":0,"likes":3,"message":"\u003cp>Nice article! Some thoughts:\u003c/p>\u003cp>1) Seems like there is still no systematic way to choose a good reward function, for any task in general. Perhaps we should examine the idea of learning as an optimization (of some reward function) itself? Why do we think AGI will be based on optimization?\u003c/p>\u003cp>2) We still don't really know, in general, what the machine learn in a given task. \u003cbr>In the Atari example, do the machine learn to play Atari game in general or only that specific Atari - what if we change the pixel colors or object shapes and add in new obstacles. How much more data does it require to learn to play as well as before?\u003cbr>I think this is closely related to the issue of Explainable AI.\u003c/p>","id":"3851368521","createdAt":"2018-04-12T08:01:18","author":{"username":"tytung","about":"","name":"Daniel80","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2011-03-05T02:26:51","profileUrl":"https://disqus.com/by/tytung/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"7855253","avatar":{"permalink":"https://disqus.com/api/users/avatars/tytung.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/tytung.jpg","cache":"https://c.disquscdn.com/uploads/users/785/5253/avatar128.jpg?1490175978"},"cache":"https://c.disquscdn.com/uploads/users/785/5253/avatar92.jpg?1490175978","large":{"permalink":"https://disqus.com/api/users/avatars/tytung.jpg","cache":"https://c.disquscdn.com/uploads/users/785/5253/avatar92.jpg?1490175978"},"small":{"permalink":"https://disqus.com/api/users/avatars/tytung.jpg","cache":"https://c.disquscdn.com/uploads/users/785/5253/avatar32.jpg?1490175978"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Nice article! Some thoughts:\n\n1) Seems like there is still no systematic way to choose a good reward function, for any task in general. Perhaps we should examine the idea of learning as an optimization (of some reward function) itself? Why do we think AGI will be based on optimization?\n\n2) We still don't really know, in general, what the machine learn in a given task. \nIn the Atari example, do the machine learn to play Atari game in general or only that specific Atari - what if we change the pixel colors or object shapes and add in new obstacles. How much more data does it require to learn to play as well as before?\nI think this is closely related to the issue of Explainable AI.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":3,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-02-23T10:41:18","dislikes":0,"thread":"6479477416","numReports":0,"likes":3,"message":"\u003cp>Just like Alphazero gets compared to Stockfish, it would be fair to compare the super smash brothers RL bot to a different AI made using non RL techniques. \u003cbr>\u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Do1bfQWy8o08%3AG7UAAEWOBiUpA6JQTBjzvNgWz4c&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://www.youtube.com/watch?v=o1bfQWy8o08\">https://www.youtube.com/wat...\u003c/a>\u003c/p>\u003cp>Note how much better the bot performs against the humans, also while the bot was limited to playing a single character, it wasn't limited in opponents. It also had the same reaction time as the deep RL program.\u003c/p>\u003cp>You can look at the source code here \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fgithub.com%2Faltf4%2FSmashBot%3A-0aZUArzij3jRXSv4IjfWXz5iy0&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://github.com/altf4/SmashBot\">https://github.com/altf4/Sm...\u003c/a> and you can look at its self play matches here \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkxwPr9oxUMw%26feature%3Dyoutu.be%3AOKAd0jQVVWlL85wLaQw2pRF_5-M&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://www.youtube.com/watch?v=kxwPr9oxUMw&amp;feature=youtu.be\">https://www.youtube.com/wat...\u003c/a>\u003c/p>\u003cp>As we can tell, Smashbot (the one designed by non RL techniques) is Vastly superior to Philip (the bot built using RL)\u003c/p>","id":"3761002660","createdAt":"2018-02-16T10:41:18","author":{"username":"disqus_rJVUqgJpkq","about":"","name":"Edmund Nelson","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2017-02-27T08:06:13","profileUrl":"https://disqus.com/by/disqus_rJVUqgJpkq/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"243710184","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_rJVUqgJpkq.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_rJVUqgJpkq.jpg","cache":"https://c.disquscdn.com/uploads/users/24371/184/avatar200.jpg?1643143374"},"cache":"https://c.disquscdn.com/uploads/users/24371/184/avatar92.jpg?1643143374","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_rJVUqgJpkq.jpg","cache":"https://c.disquscdn.com/uploads/users/24371/184/avatar92.jpg?1643143374"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_rJVUqgJpkq.jpg","cache":"https://c.disquscdn.com/uploads/users/24371/184/avatar32.jpg?1643143374"},"isCustom":true}},"media":[{"providerName":"YouTube","resolvedUrl":"http://www.youtube.com/watch?v=kxwPr9oxUMw","thumbnailUrl":"//a.disquscdn.com/get?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FkxwPr9oxUMw%2Fhqdefault.jpg&key=v3a0lNLuvgNDhpF1IpQzug","htmlHeight":480,"id":37203219,"thumbnailWidth":480,"title":"SmashBot vs SmashBot","htmlWidth":854,"mediaType":"3","html":"\u003ciframe width=\"854\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FkxwPr9oxUMw%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkxwPr9oxUMw&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FkxwPr9oxUMw%2Fhqdefault.jpg&amp;key=21d07d84db7f4d66a55297735025d6d1&amp;type=text%2Fhtml&amp;schema=youtube\" height=\"480\" scrolling=\"no\" frameborder=\"no\">\u003c/iframe>","location":"kxwPr9oxUMw","type":"2","metadata":{"create_method":"preview","thumbnail":"//a.disquscdn.com/get?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FkxwPr9oxUMw%2Fhqdefault.jpg&key=v3a0lNLuvgNDhpF1IpQzug"},"urlRedirect":"https://disq.us/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkxwPr9oxUMw%26feature%3Dyoutu.be%3AOKAd0jQVVWlL85wLaQw2pRF_5-M&cuid=3902136","description":"SmashBot fights itself in a cool and strangely beautiful way...","post":"3761002660","thumbnailURL":"//a.disquscdn.com/get?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2FkxwPr9oxUMw%2Fhqdefault.jpg&key=v3a0lNLuvgNDhpF1IpQzug","thread":"6479477416","forum":"kindasortainsightful","url":"https://www.youtube.com/watch?v=kxwPr9oxUMw&feature=youtu.be","resolvedUrlRedirect":"http://disq.us/url?url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkxwPr9oxUMw%3AAmGjo2T8sy9mw-XCvlVHuCC6DuA&cuid=3902136","thumbnailHeight":360},{"providerName":"YouTube","resolvedUrl":"http://www.youtube.com/watch?v=o1bfQWy8o08","thumbnailUrl":"//a.disquscdn.com/get?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fo1bfQWy8o08%2Fhqdefault.jpg&key=1iKPn6fvCXfRhikRnIxRVw","htmlHeight":480,"id":37202991,"thumbnailWidth":480,"title":"STR 2017 SSBM - Smashbot VS The Pros","htmlWidth":854,"mediaType":"3","html":"\u003ciframe width=\"854\" src=\"//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fo1bfQWy8o08%3Ffeature%3Doembed&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Do1bfQWy8o08&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fo1bfQWy8o08%2Fhqdefault.jpg&amp;key=21d07d84db7f4d66a55297735025d6d1&amp;type=text%2Fhtml&amp;schema=youtube\" height=\"480\" scrolling=\"no\" frameborder=\"no\">\u003c/iframe>","location":"o1bfQWy8o08","type":"2","metadata":{"create_method":"preview","thumbnail":"//a.disquscdn.com/get?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fo1bfQWy8o08%2Fhqdefault.jpg&key=1iKPn6fvCXfRhikRnIxRVw"},"urlRedirect":"https://disq.us/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Do1bfQWy8o08%3AG7UAAEWOBiUpA6JQTBjzvNgWz4c&cuid=3902136","description":"Smash The Record 2017 - Ontario, California | 9/14 - 17/2017 Live Broadcast By VGBootCamp: http://www.twitch.tv/vgbootcamp Subscribe to VGBootCamp's Channel for more Smash Bros. Tournament Matches! For Brackets: https://smash.gg/tournament/smash-the-record-2017-1/events -- Watch live at https://www.twitch.tv/vgbootcamp","post":"3761002660","thumbnailURL":"//a.disquscdn.com/get?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fo1bfQWy8o08%2Fhqdefault.jpg&key=1iKPn6fvCXfRhikRnIxRVw","thread":"6479477416","forum":"kindasortainsightful","url":"https://www.youtube.com/watch?v=o1bfQWy8o08","resolvedUrlRedirect":"http://disq.us/url?url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Do1bfQWy8o08%3AkkkjlJJdB07hn20w5oxMBJAfkns&cuid=3902136","thumbnailHeight":360}],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Just like Alphazero gets compared to Stockfish, it would be fair to compare the super smash brothers RL bot to a different AI made using non RL techniques. \nhttps://www.youtube.com/watch?v=o1bfQWy8o08\n\nNote how much better the bot performs against the humans, also while the bot was limited to playing a single character, it wasn't limited in opponents. It also had the same reaction time as the deep RL program.\n\nYou can look at the source code here https://github.com/altf4/SmashBot and you can look at its self play matches here https://www.youtube.com/watch?v=kxwPr9oxUMw&feature=youtu.be\n\n\nAs we can tell, Smashbot (the one designed by non RL techniques) is Vastly superior to Philip (the bot built using RL)","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":3,"moderationLabels":["links","media"],"isEdited":false,"sb":false},{"editableUntil":"2018-02-22T14:35:21","dislikes":0,"thread":"6479477416","numReports":0,"likes":3,"message":"\u003cp>&gt; \"the fact that this needed 6400 CPU hours is a bit disheartening\"\u003cbr>Approximately same amount of hours as it takes a baby to learn to walk. Not sure how baby CPU hours compare to silicone CPU hours and all that, but maybe not as disheartening after all.\u003c/p>","id":"3759433848","createdAt":"2018-02-15T14:35:21","author":{"username":"ilyakuzovkin","about":"PhD candidate in Neuroscience and AI at University of Tartu. Machine Learning Architect at OffWorld.","name":"Ilya Kuzovkin","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-02-27T00:29:53","profileUrl":"https://disqus.com/by/ilyakuzovkin/","url":"http://www.ikuz.eu","location":"Sydney","isPrivate":false,"signedUrl":"http://disq.us/?url=http%3A%2F%2Fwww.ikuz.eu&key=okxRkbGSH3o6L4EIXJK6mg","isPrimary":true,"isAnonymous":false,"id":"146146884","avatar":{"permalink":"https://disqus.com/api/users/avatars/ilyakuzovkin.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/ilyakuzovkin.jpg","cache":"https://c.disquscdn.com/uploads/users/14614/6884/avatar128.jpg?1582429584"},"cache":"https://c.disquscdn.com/uploads/users/14614/6884/avatar92.jpg?1582429584","large":{"permalink":"https://disqus.com/api/users/avatars/ilyakuzovkin.jpg","cache":"https://c.disquscdn.com/uploads/users/14614/6884/avatar92.jpg?1582429584"},"small":{"permalink":"https://disqus.com/api/users/avatars/ilyakuzovkin.jpg","cache":"https://c.disquscdn.com/uploads/users/14614/6884/avatar32.jpg?1582429584"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"> \"the fact that this needed 6400 CPU hours is a bit disheartening\"\nApproximately same amount of hours as it takes a baby to learn to walk. Not sure how baby CPU hours compare to silicone CPU hours and all that, but maybe not as disheartening after all.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":3,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-03-04T02:20:54","dislikes":0,"thread":"6479477416","numReports":0,"likes":2,"message":"\u003cp>Thanks for taking the time to write such a comprehensive and thoughtful post!\u003c/p>","id":"3774858261","createdAt":"2018-02-25T02:20:54","author":{"username":"franciscobalart","about":"","name":"Francisco Balart","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-07-24T03:39:04","profileUrl":"https://disqus.com/by/franciscobalart/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"63901655","avatar":{"permalink":"https://disqus.com/api/users/avatars/franciscobalart.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/franciscobalart.jpg","cache":"https://c.disquscdn.com/uploads/users/6390/1655/avatar128.jpg?1519525255"},"cache":"https://c.disquscdn.com/uploads/users/6390/1655/avatar92.jpg?1519525255","large":{"permalink":"https://disqus.com/api/users/avatars/franciscobalart.jpg","cache":"https://c.disquscdn.com/uploads/users/6390/1655/avatar92.jpg?1519525255"},"small":{"permalink":"https://disqus.com/api/users/avatars/franciscobalart.jpg","cache":"https://c.disquscdn.com/uploads/users/6390/1655/avatar32.jpg?1519525255"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for taking the time to write such a comprehensive and thoughtful post!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":2,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-02-22T11:57:00","dislikes":0,"thread":"6479477416","numReports":0,"likes":2,"message":"\u003cp>Thanks for the write-up! Most of it rings true for me. In particular, forward models are likely necessary if you want low sample-complexity, and they have the double-whammy effect of allowing you to learn a representation based on the easier task of prediction, rather than a noisy RL signal. Although I think the biggest gains are going to come when we manage to properly unlock efficient exploration.\u003c/p>\u003cp>Just to add my own two cents, the more I work with DRL, the more I'm convinced that deep neural networks are simply awful choices for doing reinforcement learning (well, mainly Q-learning). Slow updates are a death sentence in value-learning, where you need to do a lot of bootstrapping and temporal back-ups (and having to sample from old samples in a replay memory doesn't help). Additionally, during training, the intermediates value function landscape is not smooth, and constantly changing ( see \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F1018-generalization-in-reinforcement-learning-safely-approximating-the-value-function.pdf%3AVPQm_jASfEmpjj7lp5s3rJIvbbk&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://papers.nips.cc/paper/1018-generalization-in-reinforcement-learning-safely-approximating-the-value-function.pdf\">https://papers.nips.cc/pape...\u003c/a> ) which is likely difficult for networks to capture efficiently. MFEC ( \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.04460%3AmLGzHrTFLV5fpQOaoYXgGMy8nSk&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://arxiv.org/abs/1606.04460\">https://arxiv.org/abs/1606....\u003c/a> ) and NEC ( \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1703.01988%3AdyKJDCs6msS3HczDaL11_31D76Y&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://arxiv.org/abs/1703.01988\">https://arxiv.org/abs/1703....\u003c/a> ) show that you can learn a lot more quickly via 'shallow' methods.\u003c/p>\u003cp>Of course, the power of deep learning is being able to find representations of the data which make shallow learning (e.g. the last layer of the network) trivial. And obviously this is good enough that DQN eventually overtakes NEC. The ideal system would seem to be something along the lines of NEC, where a DNN is used to provide a representation for a more traditional learner (e.g. gaussian process). However, it seems like training this DNN alongside the simple learner is difficult (NEC does make an attempt, but, from what I understand, the method is not very well motivated). As well as finding a suitable loss function, you also have to deal with what is effectively a changing environment for the simple learner. One idea that I was quite interested is combining a short term simple learner with long term network learning (e.g. \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1801.01968%3AFawLBX5v0V3dSmAz93NmjFlHf88&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://arxiv.org/abs/1801.01968\">https://arxiv.org/abs/1801....\u003c/a> ), so the learner is able to quickly learn new skills, but then is able to learn to generalise them using a deep learner. I'm actually surprised that Deepmind hasn't followed up more on this idea, as my impressions is that this was the motivation for MFEC/NEC in the first place.\u003c/p>\u003cp>But yeah, tl;dr: If deep learning is alchemy, then deep RL is black magic.\u003c/p>","id":"3759245981","createdAt":"2018-02-15T11:57:00","author":{"username":"williamwoof","about":"","name":"William Woof","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2016-05-30T12:47:57","profileUrl":"https://disqus.com/by/williamwoof/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"209878265","avatar":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for the write-up! Most of it rings true for me. In particular, forward models are likely necessary if you want low sample-complexity, and they have the double-whammy effect of allowing you to learn a representation based on the easier task of prediction, rather than a noisy RL signal. Although I think the biggest gains are going to come when we manage to properly unlock efficient exploration.\n\nJust to add my own two cents, the more I work with DRL, the more I'm convinced that deep neural networks are simply awful choices for doing reinforcement learning (well, mainly Q-learning). Slow updates are a death sentence in value-learning, where you need to do a lot of bootstrapping and temporal back-ups (and having to sample from old samples in a replay memory doesn't help). Additionally, during training, the intermediates value function landscape is not smooth, and constantly changing ( see https://papers.nips.cc/paper/1018-generalization-in-reinforcement-learning-safely-approximating-the-value-function.pdf ) which is likely difficult for networks to capture efficiently. MFEC ( https://arxiv.org/abs/1606.04460 ) and NEC ( https://arxiv.org/abs/1703.01988 ) show that you can learn a lot more quickly via 'shallow' methods.\n\nOf course, the power of deep learning is being able to find representations of the data which make shallow learning (e.g. the last layer of the network) trivial. And obviously this is good enough that DQN eventually overtakes NEC. The ideal system would seem to be something along the lines of NEC, where a DNN is used to provide a representation for a more traditional learner (e.g. gaussian process). However, it seems like training this DNN alongside the simple learner is difficult (NEC does make an attempt, but, from what I understand, the method is not very well motivated). As well as finding a suitable loss function, you also have to deal with what is effectively a changing environment for the simple learner. One idea that I was quite interested is combining a short term simple learner with long term network learning (e.g. https://arxiv.org/abs/1801.01968 ), so the learner is able to quickly learn new skills, but then is able to learn to generalise them using a deep learner. I'm actually surprised that Deepmind hasn't followed up more on this idea, as my impressions is that this was the motivation for MFEC/NEC in the first place.\n\nBut yeah, tl;dr: If deep learning is alchemy, then deep RL is black magic.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":2,"moderationLabels":["links"],"isEdited":true,"sb":false},{"editableUntil":"2018-02-28T22:33:39","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>Maybe you'd be interested in this: \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322287498_Continuous_reinforcement_learning_with_incremental_Gaussian_mixture_models%3AuoXwouioG0kBzzVvj4yZRfEmCjA&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://www.researchgate.net/publication/322287498_Continuous_reinforcement_learning_with_incremental_Gaussian_mixture_models\">https://www.researchgate.ne...\u003c/a>\u003c/p>\u003cp>It uses shallow Gaussian Mixture Models for Q-Learning and is highly sample efficient. Unfortunately, due to time and hardware limitations, only small toy environments were tested (more complex environments coming soon). Nevertheless, it seems like there is a pattern there, when we consider similarities to MFEC and NEC.\u003c/p>","id":"3769901149","createdAt":"2018-02-21T22:33:39","author":{"username":"disqus_5vVq9AQsLv","about":"Neural Networks Researcher","name":"Rafael Pinto","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2014-07-06T20:06:21","profileUrl":"https://disqus.com/by/disqus_5vVq9AQsLv/","url":"","location":"Canoas, RS","isPrivate":true,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"113365837","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_5vVq9AQsLv.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_5vVq9AQsLv.jpg","cache":"https://c.disquscdn.com/uploads/users/11336/5837/avatar128.jpg?1404677266"},"cache":"https://c.disquscdn.com/uploads/users/11336/5837/avatar92.jpg?1404677266","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_5vVq9AQsLv.jpg","cache":"https://c.disquscdn.com/uploads/users/11336/5837/avatar92.jpg?1404677266"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_5vVq9AQsLv.jpg","cache":"https://c.disquscdn.com/uploads/users/11336/5837/avatar32.jpg?1404677266"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3759245981,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Maybe you'd be interested in this: https://www.researchgate.net/publication/322287498_Continuous_reinforcement_learning_with_incremental_Gaussian_mixture_models\n\nIt uses shallow Gaussian Mixture Models for Q-Learning and is highly sample efficient. Unfortunately, due to time and hardware limitations, only small toy environments were tested (more complex environments coming soon). Nevertheless, it seems like there is a pattern there, when we consider similarities to MFEC and NEC.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":1,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-02-25T06:47:09","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>The paper 'shallow updates for deep reinforcement learning' (\u003ca href=\"https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1705.07461%29%3AIAUilD17yS1kMY_YALZyo6f8UQQ&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://arxiv.org/abs/1705.07461)\">https://arxiv.org/abs/1705....\u003c/a> does exactly that - combines DQN for learning representations with a linear batch RL algorithm for the last layer.\u003c/p>","id":"3763957679","createdAt":"2018-02-18T06:47:09","author":{"username":"avivtamar","about":"","name":"Aviv Tamar","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-02-18T06:45:34","profileUrl":"https://disqus.com/by/avivtamar/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"280448445","avatar":{"permalink":"https://disqus.com/api/users/avatars/avivtamar.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/avivtamar.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/avivtamar.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/avivtamar.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3759245981,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"The paper 'shallow updates for deep reinforcement learning' (https://arxiv.org/abs/1705.07461) does exactly that - combines DQN for learning representations with a linear batch RL algorithm for the last layer.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":1,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-02-26T11:24:07","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>Yes, I remember seeing this paper, although a long time before I realised the true importance of it. My one critique would be that it still uses linear approximation for the shallow part, which is not great for value-function approximation while training.\u003c/p>\u003cp>It's a shame a lot of this sort of work tends to get buried due to the big players setting the status quo (not really their fault, although I'd like to see more recognition of the problem of small labs having to do research on similar problems). Stability and predictability (which you can partially overcome with enough compute) are one of the biggest barriers to doing research in RL right now, in my opinion.\u003c/p>","id":"3765557638","createdAt":"2018-02-19T11:24:07","author":{"username":"williamwoof","about":"","name":"William Woof","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2016-05-30T12:47:57","profileUrl":"https://disqus.com/by/williamwoof/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"209878265","avatar":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/williamwoof.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3763957679,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Yes, I remember seeing this paper, although a long time before I realised the true importance of it. My one critique would be that it still uses linear approximation for the shallow part, which is not great for value-function approximation while training.\n\n\n\nIt's a shame a lot of this sort of work tends to get buried due to the big players setting the status quo (not really their fault, although I'd like to see more recognition of the problem of small labs having to do research on similar problems). Stability and predictability (which you can partially overcome with enough compute) are one of the biggest barriers to doing research in RL right now, in my opinion.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":2,"points":1,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-11-22T11:54:15","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>To add to the practical usage of Deep RL list, I'd point our latest work *Classification with Costly Features using Deep Reinforcement Learning* (\u003ca href=\"https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1711.07364%3ANEvE8Lmenr0dHNjNwI0teCmvUBw&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://arxiv.org/abs/1711.07364\">https://arxiv.org/abs/1711....\u003c/a>, to appear at AAAI 2019).\u003c/p>","id":"4196190177","createdAt":"2018-11-15T11:54:15","author":{"username":"jaromiru","about":"","name":"Jarom\u00edr Janisch","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2016-09-24T11:04:19","profileUrl":"https://disqus.com/by/jaromiru/","url":"http://jaromiru.com","location":"","isPrivate":false,"signedUrl":"http://disq.us/?url=http%3A%2F%2Fjaromiru.com&key=D-mxHzbg_R8x0tIMw5950A","isPrimary":true,"isAnonymous":false,"id":"224234520","avatar":{"permalink":"https://disqus.com/api/users/avatars/jaromiru.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/jaromiru.jpg","cache":"https://c.disquscdn.com/uploads/users/22423/4520/avatar128.jpg?1548901516"},"cache":"https://c.disquscdn.com/uploads/users/22423/4520/avatar92.jpg?1548901516","large":{"permalink":"https://disqus.com/api/users/avatars/jaromiru.jpg","cache":"https://c.disquscdn.com/uploads/users/22423/4520/avatar92.jpg?1548901516"},"small":{"permalink":"https://disqus.com/api/users/avatars/jaromiru.jpg","cache":"https://c.disquscdn.com/uploads/users/22423/4520/avatar32.jpg?1548901516"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"To add to the practical usage of Deep RL list, I'd point our latest work *Classification with Costly Features using Deep Reinforcement Learning* (https://arxiv.org/abs/1711.07364, to appear at AAAI 2019).","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":1,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-10-24T00:52:58","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>Absolutely great article, humorous and informative. Helped me a ton on picking a topic for my RL project. Thanks for all the great references and link!\u003c/p>","id":"4148604367","createdAt":"2018-10-17T00:52:58","author":{"username":"zhenstephengou","about":"","name":"Zhen Stephen Gou","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-10-17T00:52:51","profileUrl":"https://disqus.com/by/zhenstephengou/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"323704319","avatar":{"permalink":"https://disqus.com/api/users/avatars/zhenstephengou.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/zhenstephengou.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/zhenstephengou.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/zhenstephengou.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Absolutely great article, humorous and informative. Helped me a ton on picking a topic for my RL project. Thanks for all the great references and link!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":1,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-05-25T09:36:21","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>Maybe one approach is to have the agent also try to predict the future and convince a classifier that its predictions are realistic?\u003c/p>\u003cp>And further still, maybe they can win through illegal moves IFF the classifier doesn't call their bluff?\u003c/p>\u003cp>So the agent has two jobs while the classifier has one. The agent is NOT being graded on the objective. Instead, the agent is grading itself on winning against its own imagination, whilst trying to convince a classifier that everything it did was realistic.\u003c/p>\u003cp>Basically, the goal is to get the model good enough to permanently curbstomp the classifier, meanwhile training the agent to win in a world of pure imagination.\u003c/p>\u003cp>Maybe even make BOTH a prerequisite to any sort of scoring? I.E. the agent MUST win in its imaginary environment, AND the classifier has to accept such wonderland physics as being realistic. Thus, wonderland physics need to be both easily-learnable and reasonably-convincing to the ever-more-capable classifier?\u003c/p>\u003cp>Of course, we do need to worry about the classifier initially becoming very skilled at discerning realty from the fictional wonderland the agent operates in, so maybe the classifier should only be punished for letting the agent get away with it, that way the agent will have to repeatedly rethink the moves against its imagination and their results until it has something where the classifier lets it through, so that the classifier is held back from curbstomping and then overfitting the agent?\u003c/p>","id":"3906154689","createdAt":"2018-05-18T09:36:21","author":{"username":"petersmythe","about":"","name":"Peter Smythe","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-06-23T10:48:26","profileUrl":"https://disqus.com/by/petersmythe/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"58561581","avatar":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar128.jpg?1371984508"},"cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar92.jpg?1371984508","large":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar92.jpg?1371984508"},"small":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar32.jpg?1371984508"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Maybe one approach is to have the agent also try to predict the future and convince a classifier that its predictions are realistic?\n\nAnd further still, maybe they can win through illegal moves IFF the classifier doesn't call their bluff?\n\nSo the agent has two jobs while the classifier has one. The agent is NOT being graded on the objective. Instead, the agent is grading itself on winning against its own imagination, whilst trying to convince a classifier that everything it did was realistic.\n\nBasically, the goal is to get the model good enough to permanently curbstomp the classifier, meanwhile training the agent to win in a world of pure imagination.\n\nMaybe even make BOTH a prerequisite to any sort of scoring? I.E. the agent MUST win in its imaginary environment, AND the classifier has to accept such wonderland physics as being realistic. Thus, wonderland physics need to be both easily-learnable and reasonably-convincing to the ever-more-capable classifier?\n\nOf course, we do need to worry about the classifier initially becoming very skilled at discerning realty from the fictional wonderland the agent operates in, so maybe the classifier should only be punished for letting the agent get away with it, that way the agent will have to repeatedly rethink the moves against its imagination and their results until it has something where the classifier lets it through, so that the classifier is held back from curbstomping and then overfitting the agent?","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":1,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2018-02-23T17:50:31","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>I interviewed RL researchers last year, including the team at MSR with the first production contextual bandit service and I couldn't find any other live production uses beyond your list either - but I think the Project Malmo Minecraft experiment space is worth a mention \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fthenewstack.io%2Freinforcement-learning-ready-real-world%2F%3AxBEebWxQo6wSDKlqJ9vDxnH4HIU&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://thenewstack.io/reinforcement-learning-ready-real-world/\">https://thenewstack.io/rein...\u003c/a>\u003c/p>","id":"3761597083","createdAt":"2018-02-16T17:50:31","author":{"username":"marybranscombe","about":"","name":"Mary Branscombe","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2013-06-17T21:54:46","profileUrl":"https://disqus.com/by/marybranscombe/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"57442928","avatar":{"permalink":"https://disqus.com/api/users/avatars/marybranscombe.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/marybranscombe.jpg","cache":"https://c.disquscdn.com/uploads/users/5744/2928/avatar128.jpg?1371506088"},"cache":"https://c.disquscdn.com/uploads/users/5744/2928/avatar92.jpg?1371506088","large":{"permalink":"https://disqus.com/api/users/avatars/marybranscombe.jpg","cache":"https://c.disquscdn.com/uploads/users/5744/2928/avatar92.jpg?1371506088"},"small":{"permalink":"https://disqus.com/api/users/avatars/marybranscombe.jpg","cache":"https://c.disquscdn.com/uploads/users/5744/2928/avatar32.jpg?1371506088"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"I interviewed RL researchers last year, including the team at MSR with the first production contextual bandit service and I couldn't find any other live production uses beyond your list either - but I think the Project Malmo Minecraft experiment space is worth a mention https://thenewstack.io/reinforcement-learning-ready-real-world/","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":1,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-02-22T00:28:03","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>In this work, the authors show that linear policies can solve most of these benchmark tasks: \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F7233-towards-generalization-and-simplicity-in-continuous-control%3Ar2a5bv5s1zTtmtpmAZWK8lSjiXc&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://papers.nips.cc/paper/7233-towards-generalization-and-simplicity-in-continuous-control\">https://papers.nips.cc/pape...\u003c/a>\u003c/p>\u003cp>It's very surprising that most people are not aware of this work, especially when talking about drawbacks of deep RL. The paper clearly demonstrates that not much progress has been made, if any, with \"deep\" RL, in continuous control!\u003c/p>","id":"3758690247","createdAt":"2018-02-15T00:28:03","author":{"username":"aravindrajeswaran","about":"","name":"Aravind Rajeswaran","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2016-05-07T04:55:44","profileUrl":"https://disqus.com/by/aravindrajeswaran/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"207170125","avatar":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar128.jpg?1518722494"},"cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar92.jpg?1518722494","large":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar92.jpg?1518722494"},"small":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar32.jpg?1518722494"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"In this work, the authors show that linear policies can solve most of these benchmark tasks: https://papers.nips.cc/paper/7233-towards-generalization-and-simplicity-in-continuous-control\n\nIt's very surprising that most people are not aware of this work, especially when talking about drawbacks of deep RL. The paper clearly demonstrates that not much progress has been made, if any, with \"deep\" RL, in continuous control!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":1,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-02-22T14:11:38","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Very Interesting. This is quite similar to Sergey Levine's work with Linear Gaussian policies that he then uses to fit a neural network. Do you plan to release an implementaton of the paper?\u003c/p>","id":"3759399080","createdAt":"2018-02-15T14:11:38","author":{"username":"disqus_AMybaeZdvM","about":"","name":"David","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2014-03-28T13:50:41","profileUrl":"https://disqus.com/by/disqus_AMybaeZdvM/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"100799014","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_AMybaeZdvM.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_AMybaeZdvM.jpg","cache":"https://c.disquscdn.com/uploads/users/10079/9014/avatar128.jpg?1396877572"},"cache":"https://c.disquscdn.com/uploads/users/10079/9014/avatar92.jpg?1396877572","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_AMybaeZdvM.jpg","cache":"https://c.disquscdn.com/uploads/users/10079/9014/avatar92.jpg?1396877572"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_AMybaeZdvM.jpg","cache":"https://c.disquscdn.com/uploads/users/10079/9014/avatar32.jpg?1396877572"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3758690247,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Very Interesting. This is quite similar to Sergey Levine's work with Linear Gaussian policies that he then uses to fit a neural network. Do you plan to release an implementaton of the paper?","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-02-22T19:21:33","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Thanks for the comment. This is actually quite different from Levine's work, in the sense that we don't use time varying linear policies. We just use one straight up linear policy in the base features (whatever is fed to the neural network) and train about 50 parameters in total. Basically, deep RL is being thrown around at problems that can be solved with linear regression in under a minute. We are planning a code release shortly -- the soft deadline for us is March 1st.\u003c/p>","id":"3759932418","createdAt":"2018-02-15T19:21:33","author":{"username":"aravindrajeswaran","about":"","name":"Aravind Rajeswaran","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2016-05-07T04:55:44","profileUrl":"https://disqus.com/by/aravindrajeswaran/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"207170125","avatar":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar128.jpg?1518722494"},"cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar92.jpg?1518722494","large":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar92.jpg?1518722494"},"small":{"permalink":"https://disqus.com/api/users/avatars/aravindrajeswaran.jpg","cache":"https://c.disquscdn.com/uploads/users/20717/125/avatar32.jpg?1518722494"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3759399080,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for the comment. This is actually quite different from Levine's work, in the sense that we don't use time varying linear policies. We just use one straight up linear policy in the base features (whatever is fed to the neural network) and train about 50 parameters in total. Basically, deep RL is being thrown around at problems that can be solved with linear regression in under a minute. We are planning a code release shortly -- the soft deadline for us is March 1st.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":2,"points":0,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2019-04-14T12:18:10","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>It is practically impossible to publish a Nature paper with linear regression...  It is so 1900's...\u003c/p>","id":"4413034999","createdAt":"2019-04-07T12:18:10","author":{"username":"disqus_bBqM5PjcHe","about":"","name":"Anselmo R. Pitombeira Neto","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2016-03-12T02:01:36","profileUrl":"https://disqus.com/by/disqus_bBqM5PjcHe/","url":"http://www.opl.ufc.br/authors/anselmo","location":"","isPrivate":false,"signedUrl":"http://disq.us/?url=http%3A%2F%2Fwww.opl.ufc.br%2Fauthors%2Fanselmo&key=2R_6g__sOQ0GIHIGuJzb0w","isPrimary":true,"isAnonymous":false,"id":"200104766","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_bBqM5PjcHe.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_bBqM5PjcHe.jpg","cache":"https://c.disquscdn.com/uploads/users/20010/4766/avatar128.jpg?1614218148"},"cache":"https://c.disquscdn.com/uploads/users/20010/4766/avatar92.jpg?1614218148","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_bBqM5PjcHe.jpg","cache":"https://c.disquscdn.com/uploads/users/20010/4766/avatar92.jpg?1614218148"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_bBqM5PjcHe.jpg","cache":"https://c.disquscdn.com/uploads/users/20010/4766/avatar32.jpg?1614218148"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":3759932418,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"It is practically impossible to publish a Nature paper with linear regression...  It is so 1900's...","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":3,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-02-21T21:43:26","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>Great stuff, thanks!\u003cbr>I think maybe it would also be worth mentioning hierarchical RL approaches, especially within the reward shaping/learning problems. Even though such learned rewards are inferior to the ones obtained by IRL and imitation, they can still generate some useful semantics.\u003c/p>","id":"3758454594","createdAt":"2018-02-14T21:43:26","author":{"username":"nemanjarakicevic","about":"","name":"Nemanja Rakicevic","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-02-14T21:43:05","profileUrl":"https://disqus.com/by/nemanjarakicevic/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"280132368","avatar":{"permalink":"https://disqus.com/api/users/avatars/nemanjarakicevic.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/nemanjarakicevic.jpg","cache":"https://c.disquscdn.com/uploads/users/28013/2368/avatar128.jpg?1518644607"},"cache":"https://c.disquscdn.com/uploads/users/28013/2368/avatar92.jpg?1518644607","large":{"permalink":"https://disqus.com/api/users/avatars/nemanjarakicevic.jpg","cache":"https://c.disquscdn.com/uploads/users/28013/2368/avatar92.jpg?1518644607"},"small":{"permalink":"https://disqus.com/api/users/avatars/nemanjarakicevic.jpg","cache":"https://c.disquscdn.com/uploads/users/28013/2368/avatar32.jpg?1518644607"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Great stuff, thanks!\nI think maybe it would also be worth mentioning hierarchical RL approaches, especially within the reward shaping/learning problems. Even though such learned rewards are inferior to the ones obtained by IRL and imitation, they can still generate some useful semantics.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":1,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2023-04-19T12:41:13","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>As others have said, fantastic article!   If possible, if not produced/developed already, might you consider an update to this article to determine if any current advancements have addressed any of the concerns listed above?   I'm a software safety engineer and beginning to look at the use of RL in safety critical environments, and from what I can tell many/most/all of your concerns are still valid.  Again - great insights that are holding up under the test of time.\u003c/p>","id":"6159925140","createdAt":"2023-04-12T12:41:13","author":{"username":"jasonrupert","about":"","name":"Jason Rupert","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2022-09-27T17:29:32","profileUrl":"https://disqus.com/by/jasonrupert/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"388203411","avatar":{"permalink":"https://disqus.com/api/users/avatars/jasonrupert.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/jasonrupert.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/jasonrupert.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/jasonrupert.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"As others have said, fantastic article!   If possible, if not produced/developed already, might you consider an update to this article to determine if any current advancements have addressed any of the concerns listed above?   I'm a software safety engineer and beginning to look at the use of RL in safety critical environments, and from what I can tell many/most/all of your concerns are still valid.  Again - great insights that are holding up under the test of time.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2022-08-30T01:54:40","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Nice post! Thanks for sharing your experience! I'm a beginner on RL. Can I translate this post into Chinese and repost it on my blog? And I will make sure to ALWAYS include your blog's link, and credit you as the original author in the description:)\u003c/p>","id":"5957546078","createdAt":"2022-08-23T01:54:40","author":{"username":"siyuandeng","about":"","name":"BaituBaitu","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2022-08-18T02:56:56","profileUrl":"https://disqus.com/by/siyuandeng/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"387046413","avatar":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar200.jpg?1660801524"},"cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar92.jpg?1660801524","large":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar92.jpg?1660801524"},"small":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar32.jpg?1660801524"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Nice post! Thanks for sharing your experience! I'm a beginner on RL. Can I translate this post into Chinese and repost it on my blog? And I will make sure to ALWAYS include your blog's link, and credit you as the original author in the description:)","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2022-08-30T05:36:36","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>If you include a link + credit me as original author, sure that's fine, although I should mention that it's been translated here by Synced \u003cbr>\u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650739470%26idx%3D1%26sn%3D8556f0261844848c62cae514cfa89103%26chksm%3D871ad770b06d5e66d2b52cf985e70ad4995a1cec5fea7390335356eaa20cd94accad5cab8c4c%26mpshare%3D1%26scene%3D1%26srcid%3D0324QepYVuwUo9Nz5jCDNmKM%26key%3D5af0cbb07289e721af94b2cbc0a98161f210666f5229d974c0eb05c3e6cda49f8da004a3e0873270f17fa82615fc2a643f26691ee3ec305e2638d5fe5806ac67917284d4afdf1625e8710a3c54dc41b6%26ascene%3D0%26uin%3DNjU3NTk2NjU%253D%26devicetype%3DiMac%2BMacBookPro13%252C1%2BOSX%2BOSX%2B10.12.4%2Bbuild%2816E195%29%26version%3D12020510%26nettype%3DWIFI%26lang%3Dzh_CN%26fontScale%3D100%26pass_ticket%3DMRhnrWm9nAaCTulkvi3wF7X3d%252BXMhaMhu00kK0ocPQs%253D%3ABxf17R2YtyGebag92ynLPN-pbFY&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650739470&amp;idx=1&amp;sn=8556f0261844848c62cae514cfa89103&amp;chksm=871ad770b06d5e66d2b52cf985e70ad4995a1cec5fea7390335356eaa20cd94accad5cab8c4c&amp;mpshare=1&amp;scene=1&amp;srcid=0324QepYVuwUo9Nz5jCDNmKM&amp;key=5af0cbb07289e721af94b2cbc0a98161f210666f5229d974c0eb05c3e6cda49f8da004a3e0873270f17fa82615fc2a643f26691ee3ec305e2638d5fe5806ac67917284d4afdf1625e8710a3c54dc41b6&amp;ascene=0&amp;uin=NjU3NTk2NjU%3D&amp;devicetype=iMac+MacBookPro13%2C1+OSX+OSX+10.12.4+build(16E195)&amp;version=12020510&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;pass_ticket=MRhnrWm9nAaCTulkvi3wF7X3d%2BXMhaMhu00kK0ocPQs%3D\">https://mp.weixin.qq.com/s?...\u003c/a>\u003c/p>","id":"5957650634","createdAt":"2022-08-23T05:36:36","author":{"username":"alexirpan","about":"","name":"alexirpan","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-11-26T20:40:20","profileUrl":"https://disqus.com/by/alexirpan/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"184457898","avatar":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":5957546078,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"If you include a link + credit me as original author, sure that's fine, although I should mention that it's been translated here by Synced \nhttps://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650739470&idx=1&sn=8556f0261844848c62cae514cfa89103&chksm=871ad770b06d5e66d2b52cf985e70ad4995a1cec5fea7390335356eaa20cd94accad5cab8c4c&mpshare=1&scene=1&srcid=0324QepYVuwUo9Nz5jCDNmKM&key=5af0cbb07289e721af94b2cbc0a98161f210666f5229d974c0eb05c3e6cda49f8da004a3e0873270f17fa82615fc2a643f26691ee3ec305e2638d5fe5806ac67917284d4afdf1625e8710a3c54dc41b6&ascene=0&uin=NjU3NTk2NjU%3D&devicetype=iMac+MacBookPro13%2C1+OSX+OSX+10.12.4+build(16E195)&version=12020510&nettype=WIFI&lang=zh_CN&fontScale=100&pass_ticket=MRhnrWm9nAaCTulkvi3wF7X3d%2BXMhaMhu00kK0ocPQs%3D","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":0,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2022-09-01T02:45:31","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Thanks for your notice! It saved my effort :)\u003c/p>","id":"5959522680","createdAt":"2022-08-25T02:45:31","author":{"username":"siyuandeng","about":"","name":"BaituBaitu","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2022-08-18T02:56:56","profileUrl":"https://disqus.com/by/siyuandeng/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"387046413","avatar":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar200.jpg?1660801524"},"cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar92.jpg?1660801524","large":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar92.jpg?1660801524"},"small":{"permalink":"https://disqus.com/api/users/avatars/siyuandeng.jpg","cache":"https://c.disquscdn.com/uploads/users/38704/6413/avatar32.jpg?1660801524"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":5957650634,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for your notice! It saved my effort :)","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":2,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2021-02-08T07:56:45","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>\"A 30% failure rate counts as working\"; can you possibly elaborate this a little further? I would have thought that even 1 success out of 10 would be enough to claim a victory. Is there a threshold instead?\u003c/p>","id":"5249731021","createdAt":"2021-02-01T07:56:45","author":{"username":"disqus_WKdYrUehMG","about":"","name":"Paolo","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2021-02-01T07:49:44","profileUrl":"https://disqus.com/by/disqus_WKdYrUehMG/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"363829291","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_WKdYrUehMG.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_WKdYrUehMG.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_WKdYrUehMG.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_WKdYrUehMG.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"\"A 30% failure rate counts as working\"; can you possibly elaborate this a little further? I would have thought that even 1 success out of 10 would be enough to claim a victory. Is there a threshold instead?","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2021-01-10T16:32:16","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Great article. There is another aspect which is somewhat overlooked by people who think that they can use RL for everything. The inbuilt assumption of RL is that the reward function is static across problem instances. This might be true for a game like chess where the goal state can be generalised relatively easily and does not change. But real-world problems often have dynamically changing goals. Both the initial state and goal condition are specific to the situation, and while humans quickly figure out what actions reach the required goal, RL will need to run through thousands of simulations again to compute the reward function again in terms of that specific goal. It is very hard to design a reward function that captures the different possible goals at one go. Problems with continuous values (energy, fuel, money) are even harder. As you said the more \"conventional\" techniques (heuristic search, local search, constraint programming etc.) often just solve these problems in a few seconds, without requiring huge data sets or thousands of simulation runs.\u003c/p>","id":"5210897725","createdAt":"2021-01-03T16:32:16","author":{"username":"disqus_jF42kWAowo","about":"","name":"Josef Bajada","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2011-05-17T18:10:40","profileUrl":"https://disqus.com/by/disqus_jF42kWAowo/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"10913332","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_jF42kWAowo.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_jF42kWAowo.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_jF42kWAowo.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_jF42kWAowo.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Great article. There is another aspect which is somewhat overlooked by people who think that they can use RL for everything. The inbuilt assumption of RL is that the reward function is static across problem instances. This might be true for a game like chess where the goal state can be generalised relatively easily and does not change. But real-world problems often have dynamically changing goals. Both the initial state and goal condition are specific to the situation, and while humans quickly figure out what actions reach the required goal, RL will need to run through thousands of simulations again to compute the reward function again in terms of that specific goal. It is very hard to design a reward function that captures the different possible goals at one go. Problems with continuous values (energy, fuel, money) are even harder. As you said the more \"conventional\" techniques (heuristic search, local search, constraint programming etc.) often just solve these problems in a few seconds, without requiring huge data sets or thousands of simulation runs.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2020-12-16T23:07:53","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>This post is a gem. Gives many good ideas. Thanks.\u003c/p>","id":"5183185292","createdAt":"2020-12-09T23:07:53","author":{"username":"disqus_mZEwfl1xMp","about":"","name":"Aashish Adhikari","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2020-12-01T00:56:53","profileUrl":"https://disqus.com/by/disqus_mZEwfl1xMp/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"360493086","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_mZEwfl1xMp.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_mZEwfl1xMp.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_mZEwfl1xMp.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_mZEwfl1xMp.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"This post is a gem. Gives many good ideas. Thanks.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2020-02-06T19:53:36","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Hi, thanks for the amazing post. I was wondering whether sample inefficency and instability might 'overlap'. For instance have you tried doubling the training length in the experiment you got working 7 times out of 10 to see if any of the badly behaving 3 pick up?\u003cbr>Thank you for any insight.\u003c/p>","id":"4777352734","createdAt":"2020-01-30T19:53:36","author":{"username":"disqus_4bLQ6NZWN6","about":"","name":"pfaz","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2015-10-13T04:42:03","profileUrl":"https://disqus.com/by/disqus_4bLQ6NZWN6/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"178350343","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_4bLQ6NZWN6.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_4bLQ6NZWN6.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_4bLQ6NZWN6.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_4bLQ6NZWN6.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Hi, thanks for the amazing post. I was wondering whether sample inefficency and instability might 'overlap'. For instance have you tried doubling the training length in the experiment you got working 7 times out of 10 to see if any of the badly behaving 3 pick up?\nThank you for any insight.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2019-12-30T23:54:28","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>I'm not sure why the article keeps saying things like \"Any time you introduce reward shaping, you introduce a chance for learning a non-optimal policy that optimizes the wrong objective.\" The reward shaping theorem guarantees this cannot happen if you use potential-based shaping rewards. See Ng, Harada, Russell, ICML99. Sometimes papers written before 2015 contain useful information!\u003c/p>","id":"4733918214","createdAt":"2019-12-23T23:54:28","author":{"username":"sidironman","about":"","name":"sid ironman","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-09-09T15:14:10","profileUrl":"https://disqus.com/by/sidironman/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"72275505","avatar":{"permalink":"https://disqus.com/api/users/avatars/sidironman.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/sidironman.jpg","cache":"https://c.disquscdn.com/uploads/users/7227/5505/avatar128.jpg?1380612412"},"cache":"https://c.disquscdn.com/uploads/users/7227/5505/avatar92.jpg?1380612412","large":{"permalink":"https://disqus.com/api/users/avatars/sidironman.jpg","cache":"https://c.disquscdn.com/uploads/users/7227/5505/avatar92.jpg?1380612412"},"small":{"permalink":"https://disqus.com/api/users/avatars/sidironman.jpg","cache":"https://c.disquscdn.com/uploads/users/7227/5505/avatar32.jpg?1380612412"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"I'm not sure why the article keeps saying things like \"Any time you introduce reward shaping, you introduce a chance for learning a non-optimal policy that optimizes the wrong objective.\" The reward shaping theorem guarantees this cannot happen if you use potential-based shaping rewards. See Ng, Harada, Russell, ICML99. Sometimes papers written before 2015 contain useful information!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2020-01-02T09:16:19","dislikes":0,"thread":"6479477416","numReports":0,"likes":1,"message":"\u003cp>I have read through Ng's 1999 paper, so let me quickly reply here.\u003c/p>\u003cp>As mentioned early on, the post is mostly about the empirical troubles of deep reinforcement learning, which is why many of the papers linked are more recent, and focus on troubles that appear more often when adding neural nets to RL.\u003c/p>\u003cp>The reward shaping theorem says that if you use potential based shaping rewards, your optimal policy is always unchanged. The math works, this is definitely true. However, this theorem says nothing about whether that optimal policy *is easy to discover via optimization*.\u003c/p>\u003cp>In practice, basically all deep RL algorithms do *not* attain the optimal policy. So the question becomes, does the reward shaping added tend to bring deep RL algorithms closer to optimal behavior? I don't believe there's a systematic study of this, but in my experience the answer has been \"no\" so far. The tendency for reward shaping is that you learn a reasonable behavior faster, but then have a hard time exploring past the bias that's created by your reward shaping.\u003c/p>","id":"4735708753","createdAt":"2019-12-26T09:16:19","author":{"username":"alexirpan","about":"","name":"alexirpan","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-11-26T20:40:20","profileUrl":"https://disqus.com/by/alexirpan/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"184457898","avatar":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/alexirpan.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":4733918214,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"I have read through Ng's 1999 paper, so let me quickly reply here.\n\nAs mentioned early on, the post is mostly about the empirical troubles of deep reinforcement learning, which is why many of the papers linked are more recent, and focus on troubles that appear more often when adding neural nets to RL.\n\nThe reward shaping theorem says that if you use potential based shaping rewards, your optimal policy is always unchanged. The math works, this is definitely true. However, this theorem says nothing about whether that optimal policy *is easy to discover via optimization*.\n\nIn practice, basically all deep RL algorithms do *not* attain the optimal policy. So the question becomes, does the reward shaping added tend to bring deep RL algorithms closer to optimal behavior? I don't believe there's a systematic study of this, but in my experience the answer has been \"no\" so far. The tendency for reward shaping is that you learn a reasonable behavior faster, but then have a hard time exploring past the bias that's created by your reward shaping.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":1,"points":1,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2019-06-14T09:17:56","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Thanks for the informative article for the students. Keep blogging such a useful information for the students.\u003c/p>","id":"4492673542","createdAt":"2019-06-07T09:17:56","author":{"username":"topassignmentforall","about":"We offer online help to students seeking additional help when completing their projects. Our experts are always there to correct and highlight areas of weakness.","name":"Top Assignment for all","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-11-10T05:36:02","profileUrl":"https://disqus.com/by/topassignmentforall/","url":"https://www.topassignmentforall.com","location":"New Delhi","isPrivate":false,"signedUrl":"https://disq.us/?url=https%3A%2F%2Fwww.topassignmentforall.com&key=afuOhew53G823GsOXAnZuA","isPrimary":true,"isAnonymous":false,"id":"324925853","avatar":{"permalink":"https://disqus.com/api/users/avatars/topassignmentforall.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/topassignmentforall.jpg","cache":"https://c.disquscdn.com/uploads/users/32492/5853/avatar128.jpg?1549883284"},"cache":"https://c.disquscdn.com/uploads/users/32492/5853/avatar92.jpg?1549883284","large":{"permalink":"https://disqus.com/api/users/avatars/topassignmentforall.jpg","cache":"https://c.disquscdn.com/uploads/users/32492/5853/avatar92.jpg?1549883284"},"small":{"permalink":"https://disqus.com/api/users/avatars/topassignmentforall.jpg","cache":"https://c.disquscdn.com/uploads/users/32492/5853/avatar32.jpg?1549883284"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for the informative article for the students. Keep blogging such a useful information for the students.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2019-01-17T17:37:02","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>A great post! It helps a lot in quickly grasping the main pitfalls of (deep) RL and identifying the challenges of making RL really applicable.  Thanks a lot!\u003c/p>","id":"4278981046","createdAt":"2019-01-10T17:37:02","author":{"username":"boranzhao","about":"","name":"Boran Zhao","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2019-01-10T17:33:22","profileUrl":"https://disqus.com/by/boranzhao/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"327381521","avatar":{"permalink":"https://disqus.com/api/users/avatars/boranzhao.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/boranzhao.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/boranzhao.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/boranzhao.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"A great post! It helps a lot in quickly grasping the main pitfalls of (deep) RL and identifying the challenges of making RL really applicable.  Thanks a lot!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-12-17T09:52:22","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>No. We don't know what we are doing so we can't teach machine thinks as us. We should only introduce it the road and it can do the remaining.\u003c/p>","id":"4233374929","createdAt":"2018-12-10T09:52:22","author":{"username":"youthoverturn","about":"","name":"youthoverturn","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-11-16T18:19:06","profileUrl":"https://disqus.com/by/youthoverturn/","url":"https://twitter.com/youthoverturn","location":"","isPrivate":false,"signedUrl":"https://disq.us/?url=https%3A%2F%2Ftwitter.com%2Fyouthoverturn&key=wuh_4-VzPUl3PC08Qd3o8w","isPrimary":true,"isAnonymous":false,"id":"82089631","avatar":{"permalink":"https://disqus.com/api/users/avatars/youthoverturn.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/youthoverturn.jpg","cache":"https://c.disquscdn.com/uploads/users/8208/9631/avatar128.jpg?1394004451"},"cache":"https://c.disquscdn.com/uploads/users/8208/9631/avatar92.jpg?1394004451","large":{"permalink":"https://disqus.com/api/users/avatars/youthoverturn.jpg","cache":"https://c.disquscdn.com/uploads/users/8208/9631/avatar92.jpg?1394004451"},"small":{"permalink":"https://disqus.com/api/users/avatars/youthoverturn.jpg","cache":"https://c.disquscdn.com/uploads/users/8208/9631/avatar32.jpg?1394004451"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"No. We don't know what we are doing so we can't teach machine thinks as us. We should only introduce it the road and it can do the remaining.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-11-13T22:35:47","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Hi\u003cbr>Great article!\u003cbr>Can you provide some sources about using RL by Audi? This topic is very interesting to me.\u003cbr>Greetings!\u003c/p>","id":"4182001928","createdAt":"2018-11-06T22:35:47","author":{"username":"spamnix","about":"","name":"Spam Nix","disable3rdPartyTrackers":true,"isPowerContributor":false,"joinedAt":"2018-11-06T22:35:24","profileUrl":"https://disqus.com/by/spamnix/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"324768034","avatar":{"permalink":"https://disqus.com/api/users/avatars/spamnix.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/spamnix.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/spamnix.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/spamnix.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Hi\nGreat article!\nCan you provide some sources about using RL by Audi? This topic is very interesting to me.\nGreetings!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-08-17T00:57:50","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Very good and still current.\u003c/p>","id":"4031843178","createdAt":"2018-08-10T00:57:50","author":{"username":"maquitomarkus2","about":"","name":"Markus Maquito","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2015-06-05T16:22:41","profileUrl":"https://disqus.com/by/maquitomarkus2/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"160500993","avatar":{"permalink":"https://disqus.com/api/users/avatars/maquitomarkus2.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/maquitomarkus2.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/maquitomarkus2.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/maquitomarkus2.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Very good and still current.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-08-02T15:48:52","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Very good summary, thanks for the insights!\u003c/p>","id":"4007473378","createdAt":"2018-07-26T15:48:52","author":{"username":"issamlaradji","about":"","name":"Issam Laradji","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2017-03-25T16:18:25","profileUrl":"https://disqus.com/by/issamlaradji/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"246711136","avatar":{"permalink":"https://disqus.com/api/users/avatars/issamlaradji.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/issamlaradji.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/issamlaradji.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/issamlaradji.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Very good summary, thanks for the insights!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-07-24T19:01:47","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Can you please share your thoughts on applicability of RL Vs Heuristics in EDA ( for VLSI) ?\u003cbr>Example: Solving a routing problem using  Heuristics Vs RL\u003c/p>","id":"3993592154","createdAt":"2018-07-17T19:01:47","author":{"username":"somanarsimhakalvala","about":"","name":"soma narsimha kalvala","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-07-17T18:55:00","profileUrl":"https://disqus.com/by/somanarsimhakalvala/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"292400487","avatar":{"permalink":"https://disqus.com/api/users/avatars/somanarsimhakalvala.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/somanarsimhakalvala.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/somanarsimhakalvala.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/somanarsimhakalvala.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Can you please share your thoughts on applicability of RL Vs Heuristics in EDA ( for VLSI) ?\nExample: Solving a routing problem using  Heuristics Vs RL","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-05-25T10:09:35","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Another approach similar to my last comment:\u003c/p>\u003cp>Is your problem hard for your agents to solve? Are you frustrated trying to get them to even know where to begin?\u003c/p>\u003cp>Then don't!\u003c/p>\u003cp>Make a GAN that invents new problems for your agents to solve, that are kept arbitrarily easy, then have it learn how to pretend those are your problem against an initially-naive classifier that gets ever-more scrutinizing.\u003c/p>","id":"3906177398","createdAt":"2018-05-18T10:09:35","author":{"username":"petersmythe","about":"","name":"Peter Smythe","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-06-23T10:48:26","profileUrl":"https://disqus.com/by/petersmythe/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"58561581","avatar":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar128.jpg?1371984508"},"cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar92.jpg?1371984508","large":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar92.jpg?1371984508"},"small":{"permalink":"https://disqus.com/api/users/avatars/petersmythe.jpg","cache":"https://c.disquscdn.com/uploads/users/5856/1581/avatar32.jpg?1371984508"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Another approach similar to my last comment:\n\nIs your problem hard for your agents to solve? Are you frustrated trying to get them to even know where to begin?\n\nThen don't!\n\nMake a GAN that invents new problems for your agents to solve, that are kept arbitrarily easy, then have it learn how to pretend those are your problem against an initially-naive classifier that gets ever-more scrutinizing.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2018-05-22T14:28:22","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Thanks for a fantastic read, very funny and I'm going to steal the \"lazy demon\" analogy for my own explanations! In my research I have continually run into the problems you describe relating to reward structure and it doesn't surprise me in the least that your colleagues developed RL solutions that were wildly unexpected. In one case of mine I had a multi-agent tagging simulation in which one agent would sit in a corner and do nothing while the other agent chased the target. The system learned this model because in the first few cases the same agent would capture the target, thus generating an incredibly early local optima (akin to the upside down cheetah example).\u003c/p>\u003cp>I think it is also worth mentioning how little we see DQNs used in robotics environments. As you mention this is likely due to the difficulty in generalizing to new environments. Any way, here is my shameless plug for my recent work which used Deep Learning from Demonstration to understand human responses in behavioral interventions (\u003ca href=\"https://disq.us/url?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322765497_Deep_Reinforcement_Learning_of_Abstract_Reasoning_from_Demonstrations%29%3ALROxrWNi_jbAIkCwIiesFAkDMWQ&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://www.researchgate.net/publication/322765497_Deep_Reinforcement_Learning_of_Abstract_Reasoning_from_Demonstrations)\">https://www.researchgate.ne...\u003c/a>\u003c/p>","id":"3901679374","createdAt":"2018-05-15T14:28:22","author":{"username":"madisonclarkturner","about":"","name":"Madison Clark-Turner","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-05-15T14:27:26","profileUrl":"https://disqus.com/by/madisonclarkturner/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"287798858","avatar":{"permalink":"https://disqus.com/api/users/avatars/madisonclarkturner.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/madisonclarkturner.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/madisonclarkturner.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/madisonclarkturner.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for a fantastic read, very funny and I'm going to steal the \"lazy demon\" analogy for my own explanations! In my research I have continually run into the problems you describe relating to reward structure and it doesn't surprise me in the least that your colleagues developed RL solutions that were wildly unexpected. In one case of mine I had a multi-agent tagging simulation in which one agent would sit in a corner and do nothing while the other agent chased the target. The system learned this model because in the first few cases the same agent would capture the target, thus generating an incredibly early local optima (akin to the upside down cheetah example).\n\nI think it is also worth mentioning how little we see DQNs used in robotics environments. As you mention this is likely due to the difficulty in generalizing to new environments. Any way, here is my shameless plug for my recent work which used Deep Learning from Demonstration to understand human responses in behavioral interventions (https://www.researchgate.net/publication/322765497_Deep_Reinforcement_Learning_of_Abstract_Reasoning_from_Demonstrations)","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-05-02T16:46:50","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>I was citing this page, but I had to google your name XD.\u003c/p>","id":"3872237104","createdAt":"2018-04-25T16:46:50","author":{"username":"maximafteniy","about":"","name":"Maxim Afteniy","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2017-07-31T08:27:13","profileUrl":"https://disqus.com/by/maximafteniy/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"260694711","avatar":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar128.jpg?1501489736"},"cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar92.jpg?1501489736","large":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar92.jpg?1501489736"},"small":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar32.jpg?1501489736"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"I was citing this page, but I had to google your name XD.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-04-04T11:55:28","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>That was a great post! Do you have any recommendations on how to tune DQN agent hyperparameters proposed on Deepminds 2015 paper? (My agent doesnt seem to improve  with epsilon greedy and target network :/ )\u003c/p>","id":"3828096946","createdAt":"2018-03-28T11:55:28","author":{"username":"maximafteniy","about":"","name":"Maxim Afteniy","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2017-07-31T08:27:13","profileUrl":"https://disqus.com/by/maximafteniy/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"260694711","avatar":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar128.jpg?1501489736"},"cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar92.jpg?1501489736","large":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar92.jpg?1501489736"},"small":{"permalink":"https://disqus.com/api/users/avatars/maximafteniy.jpg","cache":"https://c.disquscdn.com/uploads/users/26069/4711/avatar32.jpg?1501489736"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"That was a great post! Do you have any recommendations on how to tune DQN agent hyperparameters proposed on Deepminds 2015 paper? (My agent doesnt seem to improve  with epsilon greedy and target network :/ )","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":true,"sb":false},{"editableUntil":"2018-03-24T21:39:49","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Thanks for the great post! This is very interesting. I thought it might be useful to share a paper for HRL from human demonstrations. Definitely, good priors help! \u003ca href=\"https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1802.06604%3AGM35PrzdlW6CCUoQYX6UdIE-8vo&amp;cuid=3902136\" rel=\"nofollow noopener\" title=\"https://arxiv.org/abs/1802.06604\">https://arxiv.org/abs/1802....\u003c/a>\u003c/p>","id":"3811118737","createdAt":"2018-03-17T21:39:49","author":{"username":"disqus_mRTsB2KVj0","about":"","name":"HRL","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-03-17T21:38:49","profileUrl":"https://disqus.com/by/disqus_mRTsB2KVj0/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"283021196","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_mRTsB2KVj0.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_mRTsB2KVj0.jpg","cache":"https://c.disquscdn.com/uploads/users/28302/1196/avatar128.jpg?1592393948"},"cache":"https://c.disquscdn.com/uploads/users/28302/1196/avatar92.jpg?1592393948","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_mRTsB2KVj0.jpg","cache":"https://c.disquscdn.com/uploads/users/28302/1196/avatar92.jpg?1592393948"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_mRTsB2KVj0.jpg","cache":"https://c.disquscdn.com/uploads/users/28302/1196/avatar32.jpg?1592393948"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for the great post! This is very interesting. I thought it might be useful to share a paper for HRL from human demonstrations. Definitely, good priors help! https://arxiv.org/abs/1802.06604","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":["links"],"isEdited":false,"sb":false},{"editableUntil":"2018-03-11T23:56:06","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Thanks for the great article. I was wondering if you could share you code testing the pendulum. I wanted to run that myself to see how bad the situation by tweaking around the parameters. Thanks!\u003c/p>","id":"3787400513","createdAt":"2018-03-05T00:56:06","author":{"username":"disqus_JqSHarPgYx","about":"","name":"Galahad Threepwood","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2018-03-05T00:55:09","profileUrl":"https://disqus.com/by/disqus_JqSHarPgYx/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"281845462","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_JqSHarPgYx.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_JqSHarPgYx.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_JqSHarPgYx.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_JqSHarPgYx.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Thanks for the great article. I was wondering if you could share you code testing the pendulum. I wanted to run that myself to see how bad the situation by tweaking around the parameters. Thanks!","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-03-08T07:43:42","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning --I read this paper before,  but I just can not figure out how to model game experience, so that using simulated experience would be possible.      Does someone know about it ?\u003c/p>","id":"3781537278","createdAt":"2018-03-01T07:43:42","author":{"username":"junweidong","about":"","name":"Junwei Dong","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2017-10-27T06:05:08","profileUrl":"https://disqus.com/by/junweidong/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"269387840","avatar":{"permalink":"https://disqus.com/api/users/avatars/junweidong.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/junweidong.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar128.png"},"cache":"//a.disquscdn.com/1721054975/images/noavatar92.png","large":{"permalink":"https://disqus.com/api/users/avatars/junweidong.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar92.png"},"small":{"permalink":"https://disqus.com/api/users/avatars/junweidong.jpg","cache":"//a.disquscdn.com/1721054975/images/noavatar32.png"},"isCustom":false}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning --I read this paper before,  but I just can not figure out how to model game experience, so that using simulated experience would be possible.      Does someone know about it ?","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-03-04T07:04:26","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>This is really great.\u003cbr>it fits a discussion I was having with colleagues  about the AI industry and it's failure to truly represent the difficulties that exists mainly the lack of success in the various fields.\u003c/p>","id":"3775072212","createdAt":"2018-02-25T07:04:26","author":{"username":"disqus_SoX5cePsRu","about":"","name":"Sarit","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2016-01-10T09:16:28","profileUrl":"https://disqus.com/by/disqus_SoX5cePsRu/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"191495189","avatar":{"permalink":"https://disqus.com/api/users/avatars/disqus_SoX5cePsRu.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/disqus_SoX5cePsRu.jpg","cache":"https://c.disquscdn.com/uploads/users/19149/5189/avatar128.jpg?1571238633"},"cache":"https://c.disquscdn.com/uploads/users/19149/5189/avatar92.jpg?1571238633","large":{"permalink":"https://disqus.com/api/users/avatars/disqus_SoX5cePsRu.jpg","cache":"https://c.disquscdn.com/uploads/users/19149/5189/avatar92.jpg?1571238633"},"small":{"permalink":"https://disqus.com/api/users/avatars/disqus_SoX5cePsRu.jpg","cache":"https://c.disquscdn.com/uploads/users/19149/5189/avatar32.jpg?1571238633"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"This is really great.\nit fits a discussion I was having with colleagues  about the AI industry and it's failure to truly represent the difficulties that exists mainly the lack of success in the various fields.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":false,"sb":false},{"editableUntil":"2018-03-03T14:02:24","dislikes":0,"thread":"6479477416","numReports":0,"likes":0,"message":"\u003cp>Do you know of anyone involving an animal trainer - the other reinforcement learning?  \u003cbr>Even 'though there is a reward function and thousands of trials, I suspect allowing a human to also add a \"click-treat\" at appropriate points might see a vastly faster shaping process and consistent success rates.\u003c/p>","id":"3774008099","createdAt":"2018-02-24T14:02:24","author":{"username":"paulmcgee","about":"","name":"Paul McGee","disable3rdPartyTrackers":false,"isPowerContributor":false,"joinedAt":"2013-06-09T14:48:52","profileUrl":"https://disqus.com/by/paulmcgee/","url":"","location":"","isPrivate":false,"signedUrl":"","isPrimary":true,"isAnonymous":false,"id":"55671418","avatar":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","xlarge":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar128.jpg?1370789333"},"cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar92.jpg?1370789333","large":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar92.jpg?1370789333"},"small":{"permalink":"https://disqus.com/api/users/avatars/paulmcgee.jpg","cache":"https://c.disquscdn.com/uploads/users/5567/1418/avatar32.jpg?1370789333"},"isCustom":true}},"media":[],"isSpam":false,"hasMore":false,"isDeleted":false,"isDeletedByAuthor":false,"parent":null,"isApproved":true,"isNewUserNeedsApproval":false,"isFlagged":false,"raw_message":"Do you know of anyone involving an animal trainer - the other reinforcement learning?  \nEven 'though there is a reward function and thousands of trials, I suspect allowing a human to also add a \"click-treat\" at appropriate points might see a vastly faster shaping process and consistent success rates.","isAtFlagLimit":false,"isHighlighted":false,"canVote":false,"forum":"kindasortainsightful","depth":0,"points":0,"moderationLabels":[],"isEdited":true,"sb":false}],"thread":{"feed":"https://kindasortainsightful.disqus.com/deep_reinforcement_learning_doesnt_work_yet/latest.rss","clean_title":"Deep Reinforcement Learning Doesn't Work Yet","dislikes":0,"likes":135,"message":"","ratingsEnabled":false,"isSpam":false,"isDeleted":false,"category":"4204000","adsDisabled":false,"author":"184457898","id":"6479477416","signedLink":"http://disq.us/?url=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&key=KTTYjPF1h4viNYl0-ItFZA","createdAt":"2018-02-14T13:30:56","hasStreaming":false,"raw_message":"","isClosed":false,"link":"http://www.alexirpan.com/2018/02/14/rl-hard.html","slug":"deep_reinforcement_learning_doesnt_work_yet","forum":"kindasortainsightful","identifiers":["/2018/02/14/rl-hard.html"],"posts":68,"moderators":[184457898],"validateAllPosts":false,"title":"Deep Reinforcement Learning Doesn't Work Yet","highlightedPost":null}},"order":"popular"}</script>


    <div id="fixed-content"></div>

    
        <script type="text/javascript">
          var embedv2assets = window.document.createElement('script');
          embedv2assets.src = 'https://c.disquscdn.com/embedv2/latest/embedv2.js';
          embedv2assets.async = true;

          window.document.body.appendChild(embedv2assets);
        </script><script src="./embedv2.js.download" async=""></script>
    



    
        
            
<script type="text/json" id="disqus-urls">{
    "root":"//disqus.com",
    "next":"https://c.disquscdn.com/next/current"
}</script>

        
        
        <script>!function () {
            var d = document;
            var toH = d.head.appendChild.bind(d.head);

            var v = window.location.href.match(/[#&?]version=([0-9a-f]{32})/);
            var src = 'https://c.disquscdn.com/next/embed/lounge.load';
            if (v)
                src += '.' + v[1];
            src += '.js';

            var s = d.createElement('script');
            s.crossOrigin = 'anonymous';
            s.id = 'bootstrap-script';
            s.setAttribute('data-app', 'lounge');
            s.src = src;
            toH(s);

            var m = d.createElement('meta');
            m.setAttribute('http-equiv', 'Content-Security-Policy');
            m.setAttribute('content', "script-src https:;");
            toH(m);
        }();</script>
    


<script src="./common.bundle.789c57e7383f99787817dfc19bc98749.js.download"></script><div id="layout" data-tracking-area="layout"><div id="thread__container"><div><div id="thread__wrapper"><div id="placement-top" data-tracking-area="discovery-north"></div><div id="onboard" data-tracking-area="onboard"></div><div id="reactions__container"></div><div id="ratings__container"></div><div id="badges-message__container"></div><div id="global-alert"></div><div id="tos__container"></div><header id="main-nav" data-tracking-area="main-nav"><div><nav class="nav nav-primary nav-primary--refresh"><ul><li class="nav-tab nav-tab--primary tab-conversation tab-conversation--refresh active" data-role="post-count"><a class="publisher-nav-color"><span class="comment-count">68 comments</span></a></li><li class="nav-tab nav-tab--primary tab-user"><ul><li class="nav-tab nav-tab--primary notification-menu unread" data-role="notification-menu" style="display: list-item;"><a href="https://disqus.com/home/inbox/" class="notification-container" data-action="home" data-home-path="home/notifications/"><span class="notification-icon notification-icon--refresh icon-comment" aria-hidden="true"></span><span class="notification-count notification-count--refresh" data-role="notification-count">1</span></a></li><li class="nav-tab nav-tab--primary dropdown user-menu media-collapsed" data-role="logout"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="dropdown-toggle dropdown-toggle--refresh" data-toggle="dropdown" role="menuitem" name="Login"><span class="dropdown-toggle-wrapper"><span class="username username--refresh">Login</span> </span> <span class="caret caret--refresh"></span></a><ul class="dropdown-menu dropdown-menu--refresh"><li><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="auth:disqus">Disqus</a></li><li><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="auth:facebook">Facebook</a></li><li><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="auth:twitter">X (Twitter)</a></li><li><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="auth:google">Google</a></li><li><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="auth:microsoft">Microsoft</a></li><li><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="auth:apple">Apple</a></li></ul></li></ul></li></ul></nav></div></header><section id="conversation" data-role="main" data-tracking-area="main"><div id="posts"><div id="form" class="textarea-outer-wrapper--top-level"><form class="reply form-refresh form-refresh-v2"><div class="postbox"><div role="alert"></div><div class="ratings-wrapper" data-role="ratings-container"></div><div class="compose-wrapper"><div class="avatar"><span class="user user--refresh"><div>G</div></span></div><div class="textarea-outer-wrapper textarea-outer-wrapper--refresh"><div class="textarea-wrapper textarea-wrapper--embedv2" data-role="textarea" dir="auto"><div class="_container_ylcfx_1" role="presentation"><div class="_editor-container_ylcfx_37"><div class="_placeholder_s9avi_1">Join the discussion…</div><div role="textbox" aria-multiline="true" class="_editor_ylcfx_13" spellcheck="true" data-slate-editor="true" data-slate-node="value" contenteditable="true" zindex="-1" style="position: relative; white-space: pre-wrap; overflow-wrap: break-word;"><div data-slate-node="element"><span data-slate-node="text"><span data-slate-leaf="true"><span data-slate-zero-width="n" data-slate-length="0">﻿<br></span></span></span></div></div><button class="_placeholder-submit-button_ylcfx_55" aria-hidden="true" type="button">Comment</button></div><input accept="image/png,.png,image/jpeg,.jpeg,.jpg,image/gif,.gif" multiple="" type="file" tabindex="-1" style="display: none;"></div></div></div></div><div data-role="login-form"><div><div><section class="auth-section logged-out__display"><div class="connect"><h6 class="connect__heading">Log in with</h6><ul data-role="login-menu" class="services login-buttons"><li class="auth-disqus"><button type="button" data-action="auth:disqus" title="Disqus" class="connect__button" aria-label="Login with Disqus"><i class="icon-disqus"></i></button></li><li class="auth-facebook"><button type="button" data-action="auth:facebook" title="Facebook" class="connect__button" aria-label="Login with Facebook"><i class="icon-facebook-circle"></i></button></li><li class="auth-twitter"><button type="button" data-action="auth:twitter" title="X (Twitter)" class="connect__button" aria-label="Login with X (Twitter)"><i class="icon-twitter-x"></i></button></li><li class="auth-google"><button type="button" data-action="auth:google" title="Google" class="connect__button" aria-label="Login with Google"><i class="icon-google-plus-circle"></i></button></li><li class="auth-microsoft"><button type="button" data-action="auth:microsoft" title="Microsoft" class="connect__button" aria-label="Login with Microsoft"></button></li><li class="auth-apple"><button type="button" data-action="auth:apple" title="Apple" class="connect__button" aria-label="Login with Apple"></button></li></ul></div><div class="guest guest--refresh"><div class="sign-up-wrapper-refresh"><h6 class="guest-form-title guest-form-title--refresh"><span class="register-text"> or sign up with Disqus </span><span class="guest-text"> or pick a name </span></h6> <button type="button" class="help-tooltip__wrapper help-icon" name="guest_tooltip" tabindex="0"><div id="rules" class="help-tooltip__container" data-role="guest-form-tooltip"><div class="tooltip show help-tooltip"><h3 class="help-tooltip__heading">Disqus is a discussion network</h3><ul class="help-tooltip__list"><li><span>Don't be a jerk or do anything illegal. Everything is easier that way.</span></li></ul><p class="clearfix"><a href="https://docs.disqus.com/kb/terms-and-policies/" class="btn btn-small help-tooltip__button" rel="noopener noreferrer" target="_blank">Read full terms and conditions</a></p></div></div></button></div><p class="input-wrapper"><input dir="auto" type="text" placeholder="Name" name="display_name" id="view125_display_name" maxlength="30" class="input--text" aria-label="name"></p><div class="guest-details " data-role="guest-details"><p class="input-wrapper"><input dir="auto" type="email" placeholder="Email" name="email" id="view125_email" class="input--text" aria-label="email"></p><p class="input-wrapper"><input dir="auto" disabled="" type="text" class="register-text input--text" placeholder="Password" name="password" aria-label="password" id="view125_password"></p><div class="acceptance-wrapper"><label><input type="checkbox" name="tos"><span class="spacing-left-small">I agree to Disqus' <a href="https://help.disqus.com/customer/portal/articles/466260-terms-of-service" target="_blank" rel="noopener noreferrer">Terms of Service</a></span></label><label><input type="checkbox" name="privacy-policy"><span class="spacing-left-small">I consent to Disqus’ processing of my personal data, in accordance with its <a href="https://disqus.com/privacy-policy" target="_blank" rel="noopener noreferrer">Privacy Policy</a> and <a href="https://help.disqus.com/customer/portal/articles/466260-terms-of-service" target="_blank" rel="noopener noreferrer">Terms of Service</a>, (including the use of strictly necessary cookies) to the extent needed to authenticate me and enable me to post comments or use other Disqus services. I acknowledge that my personal data will be processed in the United States</span></label><label><input type="checkbox" name="data-sharing"><span class="spacing-left-small">I consent to Disqus collecting, using, and disclosing my personal data for marketing purposes, including the use of tracking cookies for cross context behavioral advertising. My personal data may be transferred to the companies listed <a href="https://help.disqus.com/en/articles/1944034-cookies-and-data-recipients" target="_blank" rel="noopener noreferrer">here</a>. I may withdraw my consent at any time by clicking <a href="https://disqus.com/data-sharing-settings/" target="_blank" rel="noopener noreferrer">here</a></span></label></div><input type="checkbox" name="author-guest" style="display: none;"><div class="g-recaptcha" data-role="grecaptcha-container"></div><div class="proceed" data-role="submit-btn-container"><button type="submit" class="proceed__button btn submit" aria-label="Next"><span class="icon-proceed"></span><div class="spinner"></div></button></div></div></div></section></div></div></div></div></form></div><div id="email-signup"></div><div id="secondary-navigation"><div data-tracking-area="secondary-nav" class="nav-secondary-refresh"><ul class="nav-secondary-refresh__list"><li class="nav-secondary-refresh__list-item"><div id="favorite-button"><div class="thread-likes"><div><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="favorite" title="Favorite this discussion" class="favorite-button-toggle favorite-button-toggle--v2 " aria-label="Favorite this discussion"><span class="label label-default"><span class="favorite-icon favorite-icon--refresh-v2 icon-heart-empty"></span></span><span class="label label-favorited"><span class="favorite-icon favorite-icon--refresh-v2 icon-heart"></span></span> <span class="label label-count-refresh label-count-refresh--v2">135</span></a><ul class="dropdown-menu dropdown-menu--coachmark pull-right"><li><div><h2 class="coachmark__heading">Discussion Favorited!</h2><p class="coachmark__description">Favoriting means this is a discussion worth sharing. It gets shared to your followers' Disqus feeds, and gives the creator kudos!</p></div> <a href="https://disqus.com/home/?utm_source=disqus_embed&amp;utm_content=recommend_btn" class="btn btn-primary coachmark__button" target="_blank" rel="noopener noreferrer">Find More Discussions</a></li></ul></div></div></div><div id="thread-share-bar" class="share-bar-refresh"><div class="thread-share-wrapper"><div class="round-delimiter"></div><span data-role="thread-share" class="thread-share-bar-buttons-refresh"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="share-button-toggle share-button-toggle--v2" data-toggle="dropdown" aria-label="Share">Share</a><ul class="share-dropdown-refresh"><li class="share-dropdown-refresh__item"><div class="share-icons-wrapper share-icons-wrapper--twitter" data-action="share:twitter"><span class="icon-twitter-x" aria-hidden="true"></span><span class="visually-hidden">Tweet this discussion</span></div></li><li class="share-dropdown-refresh__item"><div class="share-icons-wrapper share-icons-wrapper--facebook" data-action="share:facebook"><span class="icon-facebook" aria-hidden="true"></span><span class="visually-hidden">Share this discussion on Facebook</span></div></li><li class="share-dropdown-refresh__item"><div class="share-icons-wrapper share-icons-wrapper--email" data-action="share:email"><span class="icon-mail" aria-hidden="true"></span><span class="visually-hidden">Share this discussion via email</span></div></li><li class="share-dropdown-refresh__item"><div class="share-icons-wrapper share-icons-wrapper--link" data-action="copy-link" title="Click to copy discussion link"><span class="icon-link" aria-hidden="true"></span><span class="visually-hidden">Copy link to discussion</span></div></li></ul></span></div></div></li><li data-role="post-sort" class=""><ul class="sort-menu-refresh"><li class="sort-menu-refresh__item selected"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="sort" data-sort="popular">Best</a></li><li class="sort-menu-refresh__item "><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="sort" data-sort="desc">Newest</a></li><li class="sort-menu-refresh__item "><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="sort" data-sort="asc">Oldest</a></li></ul></li></ul></div></div><div id="no-posts" style="display: none;"></div><div id="highlighted-post" data-tracking-area="highlighted" class="highlighted-post" style="display: none;"></div><button class="alert alert--realtime alert--realtime--refresh alert--realtime--refresh-v2" data-role="realtime-notification" style="display: none;"></button><ul id="post-list" class="post-list"><li class="post" id="post-3758231210"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3758231210"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/arvash/" data-action="profile" data-tab="" data-username="arvash" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="382251" src="./avatar92.jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/arvash/" data-action="profile" data-tab="" data-username="arvash" target="_blank" rel="noopener noreferrer">arvash</a></span> <a data-action="follow" data-user="382251" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3758231210" data-role="relative-time" class="time-ago" title="Wednesday, February 14, 2018 9:37 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>that "cheetah" running on its back went pretty darn fast though. Was it actually slower? It seems like the solution would be to add a high cost for hitting the head/back. That's why real cheetas don't run like that.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-8" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">8</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3758231210" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q5jxre" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3758231210"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-3763765584"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3763765584"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/alexirpan/" data-action="profile" data-tab="" data-username="alexirpan" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>A</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/alexirpan/" data-action="profile" data-tab="" data-username="alexirpan" target="_blank" rel="noopener noreferrer">alexirpan</a></span> <span class="badge moderator"><span class="badge-content">Mod</span></span><a data-action="follow" data-user="184457898" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3758231210" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> arvash</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3763765584" data-role="relative-time" class="time-ago" title="Sunday, February 18, 2018 4:38 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>It moves at about 35% of the speed of the cheetah that runs right side up.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-9" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">9</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3763765584" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q8uk40" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3763765584"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-3774002236"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3774002236"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/paulmcgee/" data-action="profile" data-tab="" data-username="paulmcgee" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="55671418" src="./avatar92(1).jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/paulmcgee/" data-action="profile" data-tab="" data-username="paulmcgee" target="_blank" rel="noopener noreferrer">Paul McGee</a></span> <a data-action="follow" data-user="55671418" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3763765584" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> alexirpan</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3774002236" data-role="relative-time" class="time-ago" title="Saturday, February 24, 2018 3:56 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Solution, two model animals with some social learning. ;)</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3774002236" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qexyrg" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3774002236"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3774002236-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3763765584-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3758231210-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4187389914"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4187389914"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/robertioffe/" data-action="profile" data-tab="" data-username="robertioffe" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="144914500" src="./avatar92(2).jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/robertioffe/" data-action="profile" data-tab="" data-username="robertioffe" target="_blank" rel="noopener noreferrer">Robert Ioffe</a></span> <a data-action="follow" data-user="144914500" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4187389914" data-role="relative-time" class="time-ago" title="Friday, November 9, 2018 11:49 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>BTW, I observed the "running on the back" behavior in real life. My daughter, when she was learning to crawl, found it easier to get to the toy by lying on her back, pushing with her legs, and occasionally stopping and tilting her head backwards to see whether she was getting closer to the toy. And she was getting quite good and quite fast at it. We actually had to turn her over and encourage her to crawl "properly". So this should be considered a valid solution :)</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-9" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">9</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-1" data-action="downvote" title="" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">1</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4187389914" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1x92aqi" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4187389914"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-6364488128"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="6364488128"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/erangerenrot/" data-action="profile" data-tab="" data-username="erangerenrot" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="177487292" src="./avatar92(3).jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/erangerenrot/" data-action="profile" data-tab="" data-username="erangerenrot" target="_blank" rel="noopener noreferrer">Eran Gerenrot</a></span> <a data-action="follow" data-user="177487292" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4187389914" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> Robert Ioffe</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-6364488128" data-role="relative-time" class="time-ago" title="Friday, January 12, 2024 12:06 AM">7 months ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>I heard it's not very common but some babies learn to do that</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-6364488128" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2x992gw" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:6364488128"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-6364488128-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4187389914-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3759654366"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3759654366"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/ishandurugkar/" data-action="profile" data-tab="" data-username="ishandurugkar" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="280205521" src="./avatar92(4).jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/ishandurugkar/" data-action="profile" data-tab="" data-username="ishandurugkar" target="_blank" rel="noopener noreferrer">Ishan Durugkar</a></span> <a data-action="follow" data-user="280205521" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759654366" data-role="relative-time" class="time-ago" title="Thursday, February 15, 2018 6:46 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>This is a great blog post! I think you've captured the sentiments of every grad student trying to get Deep RL to work.</p><p>One paper that I think might be useful to add to the ones you've linked to is Deep Q-learning from Demonstrations (<a href="http://disq.us/url?url=http%3A%2F%2Fmlanctot.info%2Ffiles%2Fpapers%2Faaai18-dqfd.pdf%3A4O0b-D9aiAGcYZHtnlAbIPe5Y5s&amp;cuid=3902136" rel="nofollow noopener" title="http://mlanctot.info/files/papers/aaai18-dqfd.pdf">http://mlanctot.info/files/...</a> ).<br>This paper incorporates human demonstrations into the training data of a DQN agent to accelerate learning.</p><p>Regardless, this is some necessary and good discussion.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-5" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">5</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3759654366" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q6efvi" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3759654366"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3759654366-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3760829947"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3760829947"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/jesuscastaneda/" data-action="profile" data-tab="" data-username="jesuscastaneda" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="40076455" src="./avatar92(5).jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/jesuscastaneda/" data-action="profile" data-tab="" data-username="jesuscastaneda" target="_blank" rel="noopener noreferrer">jesuscastaneda</a></span> <a data-action="follow" data-user="40076455" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3760829947" data-role="relative-time" class="time-ago" title="Friday, February 16, 2018 9:03 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Particularly love this piece:<br>"...If your current policy explores too much you get junk data and learn nothing. Exploit too much and you burn-in behaviors that aren’t optimal."<br>Might as well be an observation of real life xD</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-4" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">4</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3760829947" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q73myj" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3760829947"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3760829947-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3851368521"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3851368521"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/tytung/" data-action="profile" data-tab="" data-username="tytung" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="7855253" src="./avatar92(6).jpg" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/tytung/" data-action="profile" data-tab="" data-username="tytung" target="_blank" rel="noopener noreferrer">Daniel80</a></span> <a data-action="follow" data-user="7855253" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3851368521" data-role="relative-time" class="time-ago" title="Thursday, April 12, 2018 11:01 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Nice article! Some thoughts:</p><p>1) Seems like there is still no systematic way to choose a good reward function, for any task in general. Perhaps we should examine the idea of learning as an optimization (of some reward function) itself? Why do we think AGI will be based on optimization?</p><p>2) We still don't really know, in general, what the machine learn in a given task. <br>In the Atari example, do the machine learn to play Atari game in general or only that specific Atari - what if we change the pixel colors or object shapes and add in new obstacles. How much more data does it require to learn to play as well as before?<br>I think this is closely related to the issue of Explainable AI.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-3" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">3</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3851368521" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1rp06yx" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3851368521"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3851368521-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3761002660"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3761002660"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_rJVUqgJpkq/" data-action="profile" data-tab="" data-username="disqus_rJVUqgJpkq" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="243710184" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_rJVUqgJpkq/" data-action="profile" data-tab="" data-username="disqus_rJVUqgJpkq" target="_blank" rel="noopener noreferrer">Edmund Nelson</a></span> <a data-action="follow" data-user="243710184" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3761002660" data-role="relative-time" class="time-ago" title="Friday, February 16, 2018 12:41 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Just like Alphazero gets compared to Stockfish, it would be fair to compare the super smash brothers RL bot to a different AI made using non RL techniques. <br><span><a href="https://disq.us/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Do1bfQWy8o08%3AG7UAAEWOBiUpA6JQTBjzvNgWz4c&amp;cuid=3902136" class="post-media-link" data-action="expand-collapse-media" rel="nofollow"><i class="icon-video"></i>STR 2017 SSBM - Smashbot VS The Pros<span class="post-media-link-domain"> — disq.us</span></a>
</span><div class="media-container">
<a class="media-button media-button-expand publisher-color publisher-border-color" href="https://www.youtube.com/watch?v=o1bfQWy8o08" rel="nofollow" target="_blank" data-action="expand" title="YouTube – STR 2017 SSBM - Smashbot VS The Pros">
<i class="icon-video publisher-background-color"></i>
Play
</a>
<a class="media-button media-button-contract publisher-color publisher-border-color" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" target="_blank" data-action="contract">
<i class="icon-cancel publisher-background-color"></i> Hide
</a>
<div class="media-content-loader" data-role="content-loader"></div>
<div data-role="content-placeholder" class="media-content-placeholder media-YouTube media-video"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="media-force-load" data-action="force-load"><i class="icon-video"></i></a>
</div>
</div></p><p>Note how much better the bot performs against the humans, also while the bot was limited to playing a single character, it wasn't limited in opponents. It also had the same reaction time as the deep RL program.</p><p>You can look at the source code here <a href="https://disq.us/url?url=https%3A%2F%2Fgithub.com%2Faltf4%2FSmashBot%3A-0aZUArzij3jRXSv4IjfWXz5iy0&amp;cuid=3902136" rel="nofollow noopener" title="https://github.com/altf4/SmashBot">https://github.com/altf4/Sm...</a> and you can look at its self play matches here <span><a href="https://disq.us/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkxwPr9oxUMw%26feature%3Dyoutu.be%3AOKAd0jQVVWlL85wLaQw2pRF_5-M&amp;cuid=3902136" class="post-media-link" data-action="expand-collapse-media" rel="nofollow"><i class="icon-video"></i>SmashBot vs SmashBot<span class="post-media-link-domain"> — disq.us</span></a>
</span><div class="media-container">
<a class="media-button media-button-expand publisher-color publisher-border-color" href="https://www.youtube.com/watch?v=kxwPr9oxUMw&amp;feature=youtu.be" rel="nofollow" target="_blank" data-action="expand" title="YouTube – SmashBot vs SmashBot">
<i class="icon-video publisher-background-color"></i>
Play
</a>
<a class="media-button media-button-contract publisher-color publisher-border-color" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" target="_blank" data-action="contract">
<i class="icon-cancel publisher-background-color"></i> Hide
</a>
<div class="media-content-loader" data-role="content-loader"></div>
<div data-role="content-placeholder" class="media-content-placeholder media-YouTube media-video"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="media-force-load" data-action="force-load"><i class="icon-video"></i></a>
</div>
</div></p><p>As we can tell, Smashbot (the one designed by non RL techniques) is Vastly superior to Philip (the bot built using RL)</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-3" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">3</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3761002660" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q77c84" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3761002660"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3761002660-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3759433848"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3759433848"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/ilyakuzovkin/" data-action="profile" data-tab="" data-username="ilyakuzovkin" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="146146884" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/ilyakuzovkin/" data-action="profile" data-tab="" data-username="ilyakuzovkin" target="_blank" rel="noopener noreferrer">Ilya Kuzovkin</a></span> <a data-action="follow" data-user="146146884" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759433848" data-role="relative-time" class="time-ago" title="Thursday, February 15, 2018 4:35 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>&gt; "the fact that this needed 6400 CPU hours is a bit disheartening"<br>Approximately same amount of hours as it takes a baby to learn to walk. Not sure how baby CPU hours compare to silicone CPU hours and all that, but maybe not as disheartening after all.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-3" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">3</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3759433848" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q69pq0" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3759433848"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3759433848-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3774858261"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3774858261"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/franciscobalart/" data-action="profile" data-tab="" data-username="franciscobalart" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="63901655" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/franciscobalart/" data-action="profile" data-tab="" data-username="franciscobalart" target="_blank" rel="noopener noreferrer">Francisco Balart</a></span> <a data-action="follow" data-user="63901655" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3774858261" data-role="relative-time" class="time-ago" title="Sunday, February 25, 2018 4:20 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for taking the time to write such a comprehensive and thoughtful post!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-2" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">2</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3774858261" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qfgb9x" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3774858261"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3774858261-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3759245981"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3759245981"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/williamwoof/" data-action="profile" data-tab="" data-username="williamwoof" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>W</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/williamwoof/" data-action="profile" data-tab="" data-username="williamwoof" target="_blank" rel="noopener noreferrer">William Woof</a></span> <a data-action="follow" data-user="209878265" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759245981" data-role="relative-time" class="time-ago" title="Thursday, February 15, 2018 1:57 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container" style="height: 374px;"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for the write-up! Most of it rings true for me. In particular, forward models are likely necessary if you want low sample-complexity, and they have the double-whammy effect of allowing you to learn a representation based on the easier task of prediction, rather than a noisy RL signal. Although I think the biggest gains are going to come when we manage to properly unlock efficient exploration.</p><p>Just to add my own two cents, the more I work with DRL, the more I'm convinced that deep neural networks are simply awful choices for doing reinforcement learning (well, mainly Q-learning). Slow updates are a death sentence in value-learning, where you need to do a lot of bootstrapping and temporal back-ups (and having to sample from old samples in a replay memory doesn't help). Additionally, during training, the intermediates value function landscape is not smooth, and constantly changing ( see <a href="https://disq.us/url?url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F1018-generalization-in-reinforcement-learning-safely-approximating-the-value-function.pdf%3AVPQm_jASfEmpjj7lp5s3rJIvbbk&amp;cuid=3902136" rel="nofollow noopener" title="https://papers.nips.cc/paper/1018-generalization-in-reinforcement-learning-safely-approximating-the-value-function.pdf">https://papers.nips.cc/pape...</a> ) which is likely difficult for networks to capture efficiently. MFEC ( <a href="https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.04460%3AmLGzHrTFLV5fpQOaoYXgGMy8nSk&amp;cuid=3902136" rel="nofollow noopener" title="https://arxiv.org/abs/1606.04460">https://arxiv.org/abs/1606....</a> ) and NEC ( <a href="https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1703.01988%3AdyKJDCs6msS3HczDaL11_31D76Y&amp;cuid=3902136" rel="nofollow noopener" title="https://arxiv.org/abs/1703.01988">https://arxiv.org/abs/1703....</a> ) show that you can learn a lot more quickly via 'shallow' methods.</p><p>Of course, the power of deep learning is being able to find representations of the data which make shallow learning (e.g. the last layer of the network) trivial. And obviously this is good enough that DQN eventually overtakes NEC. The ideal system would seem to be something along the lines of NEC, where a DNN is used to provide a representation for a more traditional learner (e.g. gaussian process). However, it seems like training this DNN alongside the simple learner is difficult (NEC does make an attempt, but, from what I understand, the method is not very well motivated). As well as finding a suitable loss function, you also have to deal with what is effectively a changing environment for the simple learner. One idea that I was quite interested is combining a short term simple learner with long term network learning (e.g. <a href="https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1801.01968%3AFawLBX5v0V3dSmAz93NmjFlHf88&amp;cuid=3902136" rel="nofollow noopener" title="https://arxiv.org/abs/1801.01968">https://arxiv.org/abs/1801....</a> ), so the learner is able to quickly learn new skills, but then is able to learn to generalise them using a deep learner. I'm actually surprised that Deepmind hasn't followed up more on this idea, as my impressions is that this was the motivation for MFEC/NEC in the first place.</p><p>But yeah, tl;dr: If deep learning is alchemy, then deep RL is black magic.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-2" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">2</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3759245981" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q65orh" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3759245981"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-3769901149"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3769901149"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_5vVq9AQsLv/" data-action="profile" data-tab="" data-username="disqus_5vVq9AQsLv" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="113365837" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_5vVq9AQsLv/" data-action="profile" data-tab="" data-username="disqus_5vVq9AQsLv" target="_blank" rel="noopener noreferrer">Rafael Pinto</a></span> </span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759245981" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> William Woof</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3769901149" data-role="relative-time" class="time-ago" title="Thursday, February 22, 2018 12:33 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Maybe you'd be interested in this: <a href="https://disq.us/url?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322287498_Continuous_reinforcement_learning_with_incremental_Gaussian_mixture_models%3AuoXwouioG0kBzzVvj4yZRfEmCjA&amp;cuid=3902136" rel="nofollow noopener" title="https://www.researchgate.net/publication/322287498_Continuous_reinforcement_learning_with_incremental_Gaussian_mixture_models">https://www.researchgate.ne...</a></p><p>It uses shallow Gaussian Mixture Models for Q-Learning and is highly sample efficient. Unfortunately, due to time and hardware limitations, only small toy environments were tested (more complex environments coming soon). Nevertheless, it seems like there is a pattern there, when we consider similarities to MFEC and NEC.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3769901149" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qci2cd" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3769901149"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3769901149-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3763957679"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3763957679"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/avivtamar/" data-action="profile" data-tab="" data-username="avivtamar" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>A</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/avivtamar/" data-action="profile" data-tab="" data-username="avivtamar" target="_blank" rel="noopener noreferrer">Aviv Tamar</a></span> <a data-action="follow" data-user="280448445" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759245981" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> William Woof</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3763957679" data-role="relative-time" class="time-ago" title="Sunday, February 18, 2018 8:47 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>The paper 'shallow updates for deep reinforcement learning' (<a href="https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1705.07461%29%3AIAUilD17yS1kMY_YALZyo6f8UQQ&amp;cuid=3902136" rel="nofollow noopener" title="https://arxiv.org/abs/1705.07461)">https://arxiv.org/abs/1705....</a> does exactly that - combines DQN for learning representations with a linear batch RL algorithm for the last layer.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3763957679" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q8yobz" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3763957679"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-3765557638"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3765557638"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/williamwoof/" data-action="profile" data-tab="" data-username="williamwoof" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>W</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/williamwoof/" data-action="profile" data-tab="" data-username="williamwoof" target="_blank" rel="noopener noreferrer">William Woof</a></span> <a data-action="follow" data-user="209878265" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3763957679" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> Aviv Tamar</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3765557638" data-role="relative-time" class="time-ago" title="Monday, February 19, 2018 1:24 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Yes, I remember seeing this paper, although a long time before I realised the true importance of it. My one critique would be that it still uses linear approximation for the shallow part, which is not great for value-function approximation while training.</p><p>It's a shame a lot of this sort of work tends to get buried due to the big players setting the status quo (not really their fault, although I'd like to see more recognition of the problem of small labs having to do research on similar problems). Stability and predictability (which you can partially overcome with enough compute) are one of the biggest barriers to doing research in RL right now, in my opinion.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3765557638" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q9wyva" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3765557638"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3765557638-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3763957679-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3759245981-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4196190177"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4196190177"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/jaromiru/" data-action="profile" data-tab="" data-username="jaromiru" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="224234520" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/jaromiru/" data-action="profile" data-tab="" data-username="jaromiru" target="_blank" rel="noopener noreferrer">Jaromír Janisch</a></span> <a data-action="follow" data-user="224234520" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4196190177" data-role="relative-time" class="time-ago" title="Thursday, November 15, 2018 1:54 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>To add to the practical usage of Deep RL list, I'd point our latest work *Classification with Costly Features using Deep Reinforcement Learning* (<a href="https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1711.07364%3ANEvE8Lmenr0dHNjNwI0teCmvUBw&amp;cuid=3902136" rel="nofollow noopener" title="https://arxiv.org/abs/1711.07364">https://arxiv.org/abs/1711....</a>, to appear at AAAI 2019).</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4196190177" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1xeax29" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4196190177"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4196190177-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4148604367"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4148604367"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/zhenstephengou/" data-action="profile" data-tab="" data-username="zhenstephengou" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>Z</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/zhenstephengou/" data-action="profile" data-tab="" data-username="zhenstephengou" target="_blank" rel="noopener noreferrer">Zhen Stephen Gou</a></span> <a data-action="follow" data-user="323704319" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4148604367" data-role="relative-time" class="time-ago" title="Wednesday, October 17, 2018 3:52 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Absolutely great article, humorous and informative. Helped me a ton on picking a topic for my RL project. Thanks for all the great references and link!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4148604367" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1wlyzm7" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4148604367"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4148604367-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3906154689"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3906154689"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/petersmythe/" data-action="profile" data-tab="" data-username="petersmythe" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="58561581" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/petersmythe/" data-action="profile" data-tab="" data-username="petersmythe" target="_blank" rel="noopener noreferrer">Peter Smythe</a></span> <a data-action="follow" data-user="58561581" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3906154689" data-role="relative-time" class="time-ago" title="Friday, May 18, 2018 12:36 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Maybe one approach is to have the agent also try to predict the future and convince a classifier that its predictions are realistic?</p><p>And further still, maybe they can win through illegal moves IFF the classifier doesn't call their bluff?</p><p>So the agent has two jobs while the classifier has one. The agent is NOT being graded on the objective. Instead, the agent is grading itself on winning against its own imagination, whilst trying to convince a classifier that everything it did was realistic.</p><p>Basically, the goal is to get the model good enough to permanently curbstomp the classifier, meanwhile training the agent to win in a world of pure imagination.</p><p>Maybe even make BOTH a prerequisite to any sort of scoring? I.E. the agent MUST win in its imaginary environment, AND the classifier has to accept such wonderland physics as being realistic. Thus, wonderland physics need to be both easily-learnable and reasonably-convincing to the ever-more-capable classifier?</p><p>Of course, we do need to worry about the classifier initially becoming very skilled at discerning realty from the fictional wonderland the agent operates in, so maybe the classifier should only be punished for letting the agent get away with it, that way the agent will have to repeatedly rethink the moves against its imagination and their results until it has something where the classifier lets it through, so that the classifier is held back from curbstomping and then overfitting the agent?</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3906154689" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1slmg8x" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3906154689"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3906154689-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3761597083"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3761597083"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/marybranscombe/" data-action="profile" data-tab="" data-username="marybranscombe" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="57442928" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/marybranscombe/" data-action="profile" data-tab="" data-username="marybranscombe" target="_blank" rel="noopener noreferrer">Mary Branscombe</a></span> <a data-action="follow" data-user="57442928" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3761597083" data-role="relative-time" class="time-ago" title="Friday, February 16, 2018 7:50 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>I interviewed RL researchers last year, including the team at MSR with the first production contextual bandit service and I couldn't find any other live production uses beyond your list either - but I think the Project Malmo Minecraft experiment space is worth a mention <a href="https://disq.us/url?url=https%3A%2F%2Fthenewstack.io%2Freinforcement-learning-ready-real-world%2F%3AxBEebWxQo6wSDKlqJ9vDxnH4HIU&amp;cuid=3902136" rel="nofollow noopener" title="https://thenewstack.io/reinforcement-learning-ready-real-world/">https://thenewstack.io/rein...</a></p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3761597083" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q7k2vv" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3761597083"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3761597083-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3758690247"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3758690247"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/aravindrajeswaran/" data-action="profile" data-tab="" data-username="aravindrajeswaran" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="207170125" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/aravindrajeswaran/" data-action="profile" data-tab="" data-username="aravindrajeswaran" target="_blank" rel="noopener noreferrer">Aravind Rajeswaran</a></span> <a data-action="follow" data-user="207170125" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3758690247" data-role="relative-time" class="time-ago" title="Thursday, February 15, 2018 2:28 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>In this work, the authors show that linear policies can solve most of these benchmark tasks: <a href="https://disq.us/url?url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F7233-towards-generalization-and-simplicity-in-continuous-control%3Ar2a5bv5s1zTtmtpmAZWK8lSjiXc&amp;cuid=3902136" rel="nofollow noopener" title="https://papers.nips.cc/paper/7233-towards-generalization-and-simplicity-in-continuous-control">https://papers.nips.cc/pape...</a></p><p>It's very surprising that most people are not aware of this work, especially when talking about drawbacks of deep RL. The paper clearly demonstrates that not much progress has been made, if any, with "deep" RL, in continuous control!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3758690247" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q5tryf" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3758690247"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-3759399080"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3759399080"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_AMybaeZdvM/" data-action="profile" data-tab="" data-username="disqus_AMybaeZdvM" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="100799014" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_AMybaeZdvM/" data-action="profile" data-tab="" data-username="disqus_AMybaeZdvM" target="_blank" rel="noopener noreferrer">David</a></span> <a data-action="follow" data-user="100799014" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3758690247" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> Aravind Rajeswaran</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759399080" data-role="relative-time" class="time-ago" title="Thursday, February 15, 2018 4:11 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Very Interesting. This is quite similar to Sergey Levine's work with Linear Gaussian policies that he then uses to fit a neural network. Do you plan to release an implementaton of the paper?</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3759399080" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q68yw8" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3759399080"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-3759932418"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3759932418"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/aravindrajeswaran/" data-action="profile" data-tab="" data-username="aravindrajeswaran" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="207170125" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/aravindrajeswaran/" data-action="profile" data-tab="" data-username="aravindrajeswaran" target="_blank" rel="noopener noreferrer">Aravind Rajeswaran</a></span> <a data-action="follow" data-user="207170125" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759399080" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> David</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759932418" data-role="relative-time" class="time-ago" title="Thursday, February 15, 2018 9:21 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for the comment. This is actually quite different from Levine's work, in the sense that we don't use time varying linear policies. We just use one straight up linear policy in the base features (whatever is fed to the neural network) and train about 50 parameters in total. Basically, deep RL is being thrown around at problems that can be solved with linear regression in under a minute. We are planning a code release shortly -- the soft deadline for us is March 1st.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3759932418" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q6kef6" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3759932418"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-4413034999"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4413034999"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_bBqM5PjcHe/" data-action="profile" data-tab="" data-username="disqus_bBqM5PjcHe" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="200104766" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_bBqM5PjcHe/" data-action="profile" data-tab="" data-username="disqus_bBqM5PjcHe" target="_blank" rel="noopener noreferrer">Anselmo R. Pitombeira Neto</a></span> <a data-action="follow" data-user="200104766" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3759932418" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> Aravind Rajeswaran</a></span></span>  <span class="post-meta" style="top: -2px;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4413034999" data-role="relative-time" class="time-ago" title="Sunday, April 7, 2019 3:18 PM">5 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>It is practically impossible to publish a Nature paper with linear regression...  It is so 1900's...</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4413034999" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/20zenlj" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4413034999"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4413034999-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3759932418-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3759399080-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3758690247-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3758454594"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3758454594"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/nemanjarakicevic/" data-action="profile" data-tab="" data-username="nemanjarakicevic" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="280132368" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/nemanjarakicevic/" data-action="profile" data-tab="" data-username="nemanjarakicevic" target="_blank" rel="noopener noreferrer">Nemanja Rakicevic</a></span> <a data-action="follow" data-user="280132368" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3758454594" data-role="relative-time" class="time-ago" title="Wednesday, February 14, 2018 11:43 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Great stuff, thanks!<br>I think maybe it would also be worth mentioning hierarchical RL approaches, especially within the reward shaping/learning problems. Even though such learned rewards are inferior to the ones obtained by IRL and imitation, they can still generate some useful semantics.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3758454594" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1q5oq4i" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3758454594"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3758454594-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-6159925140"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="6159925140"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/jasonrupert/" data-action="profile" data-tab="" data-username="jasonrupert" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>J</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/jasonrupert/" data-action="profile" data-tab="" data-username="jasonrupert" target="_blank" rel="noopener noreferrer">Jason Rupert</a></span> <a data-action="follow" data-user="388203411" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-6159925140" data-role="relative-time" class="time-ago" title="Wednesday, April 12, 2023 3:41 PM">a year ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>As others have said, fantastic article!   If possible, if not produced/developed already, might you consider an update to this article to determine if any current advancements have addressed any of the concerns listed above?   I'm a software safety engineer and beginning to look at the use of RL in safety critical environments, and from what I can tell many/most/all of your concerns are still valid.  Again - great insights that are holding up under the test of time.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-6159925140" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2tvgkno" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:6159925140"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-6159925140-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-5957546078"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="5957546078"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/siyuandeng/" data-action="profile" data-tab="" data-username="siyuandeng" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="387046413" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/siyuandeng/" data-action="profile" data-tab="" data-username="siyuandeng" target="_blank" rel="noopener noreferrer">BaituBaitu</a></span> <a data-action="follow" data-user="387046413" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5957546078" data-role="relative-time" class="time-ago" title="Tuesday, August 23, 2022 4:54 AM">2 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Nice post! Thanks for sharing your experience! I'm a beginner on RL. Can I translate this post into Chinese and repost it on my blog? And I will make sure to ALWAYS include your blog's link, and credit you as the original author in the description:)</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-5957546078" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2qiyvz2" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:5957546078"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-5957650634"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="5957650634"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/alexirpan/" data-action="profile" data-tab="" data-username="alexirpan" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>A</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/alexirpan/" data-action="profile" data-tab="" data-username="alexirpan" target="_blank" rel="noopener noreferrer">alexirpan</a></span> <span class="badge moderator"><span class="badge-content">Mod</span></span><a data-action="follow" data-user="184457898" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5957546078" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> BaituBaitu</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5957650634" data-role="relative-time" class="time-ago" title="Tuesday, August 23, 2022 8:36 AM">2 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>If you include a link + credit me as original author, sure that's fine, although I should mention that it's been translated here by Synced <br><a href="https://disq.us/url?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650739470%26idx%3D1%26sn%3D8556f0261844848c62cae514cfa89103%26chksm%3D871ad770b06d5e66d2b52cf985e70ad4995a1cec5fea7390335356eaa20cd94accad5cab8c4c%26mpshare%3D1%26scene%3D1%26srcid%3D0324QepYVuwUo9Nz5jCDNmKM%26key%3D5af0cbb07289e721af94b2cbc0a98161f210666f5229d974c0eb05c3e6cda49f8da004a3e0873270f17fa82615fc2a643f26691ee3ec305e2638d5fe5806ac67917284d4afdf1625e8710a3c54dc41b6%26ascene%3D0%26uin%3DNjU3NTk2NjU%253D%26devicetype%3DiMac%2BMacBookPro13%252C1%2BOSX%2BOSX%2B10.12.4%2Bbuild%2816E195%29%26version%3D12020510%26nettype%3DWIFI%26lang%3Dzh_CN%26fontScale%3D100%26pass_ticket%3DMRhnrWm9nAaCTulkvi3wF7X3d%252BXMhaMhu00kK0ocPQs%253D%3ABxf17R2YtyGebag92ynLPN-pbFY&amp;cuid=3902136" rel="nofollow noopener" title="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650739470&amp;idx=1&amp;sn=8556f0261844848c62cae514cfa89103&amp;chksm=871ad770b06d5e66d2b52cf985e70ad4995a1cec5fea7390335356eaa20cd94accad5cab8c4c&amp;mpshare=1&amp;scene=1&amp;srcid=0324QepYVuwUo9Nz5jCDNmKM&amp;key=5af0cbb07289e721af94b2cbc0a98161f210666f5229d974c0eb05c3e6cda49f8da004a3e0873270f17fa82615fc2a643f26691ee3ec305e2638d5fe5806ac67917284d4afdf1625e8710a3c54dc41b6&amp;ascene=0&amp;uin=NjU3NTk2NjU%3D&amp;devicetype=iMac+MacBookPro13%2C1+OSX+OSX+10.12.4+build(16E195)&amp;version=12020510&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;pass_ticket=MRhnrWm9nAaCTulkvi3wF7X3d%2BXMhaMhu00kK0ocPQs%3D">https://mp.weixin.qq.com/s?...</a></p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-5957650634" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2qj14ne" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:5957650634"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-5959522680"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="5959522680"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/siyuandeng/" data-action="profile" data-tab="" data-username="siyuandeng" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="387046413" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/siyuandeng/" data-action="profile" data-tab="" data-username="siyuandeng" target="_blank" rel="noopener noreferrer">BaituBaitu</a></span> <a data-action="follow" data-user="387046413" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5957650634" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> alexirpan</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5959522680" data-role="relative-time" class="time-ago" title="Thursday, August 25, 2022 5:45 AM">2 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for your notice! It saved my effort :)</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-5959522680" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2qk594o" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:5959522680"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-5959522680-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-5957650634-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-5957546078-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-5249731021"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="5249731021"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_WKdYrUehMG/" data-action="profile" data-tab="" data-username="disqus_WKdYrUehMG" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>P</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_WKdYrUehMG/" data-action="profile" data-tab="" data-username="disqus_WKdYrUehMG" target="_blank" rel="noopener noreferrer">Paolo</a></span> <a data-action="follow" data-user="363829291" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5249731021" data-role="relative-time" class="time-ago" title="Monday, February 1, 2021 9:56 AM">3 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>"A 30% failure rate counts as working"; can you possibly elaborate this a little further? I would have thought that even 1 success out of 10 would be enough to claim a victory. Is there a threshold instead?</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-5249731021" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2etjydp" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:5249731021"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-5249731021-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-5210897725"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="5210897725"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_jF42kWAowo/" data-action="profile" data-tab="" data-username="disqus_jF42kWAowo" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>J</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_jF42kWAowo/" data-action="profile" data-tab="" data-username="disqus_jF42kWAowo" target="_blank" rel="noopener noreferrer">Josef Bajada</a></span> <a data-action="follow" data-user="10913332" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5210897725" data-role="relative-time" class="time-ago" title="Sunday, January 3, 2021 6:32 PM">4 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Great article. There is another aspect which is somewhat overlooked by people who think that they can use RL for everything. The inbuilt assumption of RL is that the reward function is static across problem instances. This might be true for a game like chess where the goal state can be generalised relatively easily and does not change. But real-world problems often have dynamically changing goals. Both the initial state and goal condition are specific to the situation, and while humans quickly figure out what actions reach the required goal, RL will need to run through thousands of simulations again to compute the reward function again in terms of that specific goal. It is very hard to design a reward function that captures the different possible goals at one go. Problems with continuous values (energy, fuel, money) are even harder. As you said the more "conventional" techniques (heuristic search, local search, constraint programming etc.) often just solve these problems in a few seconds, without requiring huge data sets or thousands of simulation runs.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-5210897725" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2e6fmf1" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:5210897725"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-5210897725-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-5183185292"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="5183185292"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_mZEwfl1xMp/" data-action="profile" data-tab="" data-username="disqus_mZEwfl1xMp" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>A</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_mZEwfl1xMp/" data-action="profile" data-tab="" data-username="disqus_mZEwfl1xMp" target="_blank" rel="noopener noreferrer">Aashish Adhikari</a></span> <a data-action="follow" data-user="360493086" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-5183185292" data-role="relative-time" class="time-ago" title="Thursday, December 10, 2020 1:07 AM">4 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>This post is a gem. Gives many good ideas. Thanks.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-5183185292" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/2dpxnd8" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:5183185292"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-5183185292-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4777352734"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4777352734"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_4bLQ6NZWN6/" data-action="profile" data-tab="" data-username="disqus_4bLQ6NZWN6" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>P</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_4bLQ6NZWN6/" data-action="profile" data-tab="" data-username="disqus_4bLQ6NZWN6" target="_blank" rel="noopener noreferrer">pfaz</a></span> <a data-action="follow" data-user="178350343" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4777352734" data-role="relative-time" class="time-ago" title="Thursday, January 30, 2020 9:53 PM">4 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Hi, thanks for the amazing post. I was wondering whether sample inefficency and instability might 'overlap'. For instance have you tried doubling the training length in the experiment you got working 7 times out of 10 to see if any of the badly behaving 3 pick up?<br>Thank you for any insight.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4777352734" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/270b8ym" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4777352734"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4777352734-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4733918214"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4733918214"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/sidironman/" data-action="profile" data-tab="" data-username="sidironman" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="72275505" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/sidironman/" data-action="profile" data-tab="" data-username="sidironman" target="_blank" rel="noopener noreferrer">sid ironman</a></span> <a data-action="follow" data-user="72275505" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4733918214" data-role="relative-time" class="time-ago" title="Tuesday, December 24, 2019 1:54 AM">5 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>I'm not sure why the article keeps saying things like "Any time you introduce reward shaping, you introduce a chance for learning a non-optimal policy that optimizes the wrong objective." The reward shaping theorem guarantees this cannot happen if you use potential-based shaping rewards. See Ng, Harada, Russell, ICML99. Sometimes papers written before 2015 contain useful information!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4733918214" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/26agao6" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4733918214"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"><li class="post" id="post-4735708753"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4735708753"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/alexirpan/" data-action="profile" data-tab="" data-username="alexirpan" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>A</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/alexirpan/" data-action="profile" data-tab="" data-username="alexirpan" target="_blank" rel="noopener noreferrer">alexirpan</a></span> <span class="badge moderator"><span class="badge-content">Mod</span></span><a data-action="follow" data-user="184457898" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span><span class="parent-link-container"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4733918214" class="parent-link" data-role="parent-link"><i aria-label="in reply to" class="icon-forward" title="in reply to"></i> sid ironman</a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4735708753" data-role="relative-time" class="time-ago" title="Thursday, December 26, 2019 11:16 AM">5 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>I have read through Ng's 1999 paper, so let me quickly reply here.</p><p>As mentioned early on, the post is mostly about the empirical troubles of deep reinforcement learning, which is why many of the papers linked are more recent, and focus on troubles that appear more often when adding neural nets to RL.</p><p>The reward shaping theorem says that if you use potential based shaping rewards, your optimal policy is always unchanged. The math works, this is definitely true. However, this theorem says nothing about whether that optimal policy *is easy to discover via optimization*.</p><p>In practice, basically all deep RL algorithms do *not* attain the optimal policy. So the question becomes, does the reward shaping added tend to bring deep RL algorithms closer to optimal behavior? I don't believe there's a systematic study of this, but in my experience the answer has been "no" so far. The tendency for reward shaping is that you learn a reasonable behavior faster, but then have a hard time exploring past the bias that's created by your reward shaping.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-1" data-action="upvote" title="" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">1</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4735708753" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/26bio9d" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4735708753"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4735708753-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4733918214-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4492673542"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4492673542"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/topassignmentforall/" data-action="profile" data-tab="" data-username="topassignmentforall" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="324925853" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/topassignmentforall/" data-action="profile" data-tab="" data-username="topassignmentforall" target="_blank" rel="noopener noreferrer">Top Assignment for all</a></span> <a data-action="follow" data-user="324925853" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4492673542" data-role="relative-time" class="time-ago" title="Friday, June 7, 2019 12:17 PM">5 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for the informative article for the students. Keep blogging such a useful information for the students.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4492673542" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/22atl3a" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4492673542"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4492673542-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4278981046"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4278981046"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/boranzhao/" data-action="profile" data-tab="" data-username="boranzhao" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>B</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/boranzhao/" data-action="profile" data-tab="" data-username="boranzhao" target="_blank" rel="noopener noreferrer">Boran Zhao</a></span> <a data-action="follow" data-user="327381521" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4278981046" data-role="relative-time" class="time-ago" title="Thursday, January 10, 2019 7:37 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>A great post! It helps a lot in quickly grasping the main pitfalls of (deep) RL and identifying the challenges of making RL really applicable.  Thanks a lot!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4278981046" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1yrlewm" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4278981046"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4278981046-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4233374929"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4233374929"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/youthoverturn/" data-action="profile" data-tab="" data-username="youthoverturn" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="82089631" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/youthoverturn/" data-action="profile" data-tab="" data-username="youthoverturn" target="_blank" rel="noopener noreferrer">youthoverturn</a></span> <a data-action="follow" data-user="82089631" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4233374929" data-role="relative-time" class="time-ago" title="Monday, December 10, 2018 11:52 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>No. We don't know what we are doing so we can't teach machine thinks as us. We should only introduce it the road and it can do the remaining.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4233374929" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1y0fx01" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4233374929"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4233374929-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4182001928"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4182001928"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/spamnix/" data-action="profile" data-tab="" data-username="spamnix" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>S</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/spamnix/" data-action="profile" data-tab="" data-username="spamnix" target="_blank" rel="noopener noreferrer">Spam Nix</a></span> <a data-action="follow" data-user="324768034" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4182001928" data-role="relative-time" class="time-ago" title="Wednesday, November 7, 2018 12:35 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Hi<br>Great article!<br>Can you provide some sources about using RL by Audi? This topic is very interesting to me.<br>Greetings!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4182001928" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1x5utc8" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4182001928"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4182001928-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4031843178"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4031843178"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/maquitomarkus2/" data-action="profile" data-tab="" data-username="maquitomarkus2" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>M</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/maquitomarkus2/" data-action="profile" data-tab="" data-username="maquitomarkus2" target="_blank" rel="noopener noreferrer">Markus Maquito</a></span> <a data-action="follow" data-user="160500993" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4031843178" data-role="relative-time" class="time-ago" title="Friday, August 10, 2018 3:57 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Very good and still current.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4031843178" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1uoge3u" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4031843178"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4031843178-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-4007473378"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="4007473378"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/issamlaradji/" data-action="profile" data-tab="" data-username="issamlaradji" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>I</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/issamlaradji/" data-action="profile" data-tab="" data-username="issamlaradji" target="_blank" rel="noopener noreferrer">Issam Laradji</a></span> <a data-action="follow" data-user="246711136" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-4007473378" data-role="relative-time" class="time-ago" title="Thursday, July 26, 2018 6:48 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Very good summary, thanks for the insights!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-4007473378" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1u9y28y" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:4007473378"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-4007473378-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3993592154"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3993592154"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/somanarsimhakalvala/" data-action="profile" data-tab="" data-username="somanarsimhakalvala" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>S</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/somanarsimhakalvala/" data-action="profile" data-tab="" data-username="somanarsimhakalvala" target="_blank" rel="noopener noreferrer">soma narsimha kalvala</a></span> <a data-action="follow" data-user="292400487" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3993592154" data-role="relative-time" class="time-ago" title="Tuesday, July 17, 2018 10:01 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Can you please share your thoughts on applicability of RL Vs Heuristics in EDA ( for VLSI) ?<br>Example: Solving a routing problem using  Heuristics Vs RL</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3993592154" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1u1ojfe" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3993592154"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3993592154-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3906177398"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3906177398"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/petersmythe/" data-action="profile" data-tab="" data-username="petersmythe" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="58561581" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/petersmythe/" data-action="profile" data-tab="" data-username="petersmythe" target="_blank" rel="noopener noreferrer">Peter Smythe</a></span> <a data-action="follow" data-user="58561581" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3906177398" data-role="relative-time" class="time-ago" title="Friday, May 18, 2018 1:09 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Another approach similar to my last comment:</p><p>Is your problem hard for your agents to solve? Are you frustrated trying to get them to even know where to begin?</p><p>Then don't!</p><p>Make a GAN that invents new problems for your agents to solve, that are kept arbitrarily easy, then have it learn how to pretend those are your problem against an initially-naive classifier that gets ever-more scrutinizing.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3906177398" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1slmxrq" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3906177398"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3906177398-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3901679374"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3901679374"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/madisonclarkturner/" data-action="profile" data-tab="" data-username="madisonclarkturner" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>M</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/madisonclarkturner/" data-action="profile" data-tab="" data-username="madisonclarkturner" target="_blank" rel="noopener noreferrer">Madison Clark-Turner</a></span> <a data-action="follow" data-user="287798858" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3901679374" data-role="relative-time" class="time-ago" title="Tuesday, May 15, 2018 5:28 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for a fantastic read, very funny and I'm going to steal the "lazy demon" analogy for my own explanations! In my research I have continually run into the problems you describe relating to reward structure and it doesn't surprise me in the least that your colleagues developed RL solutions that were wildly unexpected. In one case of mine I had a multi-agent tagging simulation in which one agent would sit in a corner and do nothing while the other agent chased the target. The system learned this model because in the first few cases the same agent would capture the target, thus generating an incredibly early local optima (akin to the upside down cheetah example).</p><p>I think it is also worth mentioning how little we see DQNs used in robotics environments. As you mention this is likely due to the difficulty in generalizing to new environments. Any way, here is my shameless plug for my recent work which used Deep Learning from Demonstration to understand human responses in behavioral interventions (<a href="https://disq.us/url?url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F322765497_Deep_Reinforcement_Learning_of_Abstract_Reasoning_from_Demonstrations%29%3ALROxrWNi_jbAIkCwIiesFAkDMWQ&amp;cuid=3902136" rel="nofollow noopener" title="https://www.researchgate.net/publication/322765497_Deep_Reinforcement_Learning_of_Abstract_Reasoning_from_Demonstrations)">https://www.researchgate.ne...</a></p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3901679374" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1siyj2m" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3901679374"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3901679374-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3872237104"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3872237104"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/maximafteniy/" data-action="profile" data-tab="" data-username="maximafteniy" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="260694711" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/maximafteniy/" data-action="profile" data-tab="" data-username="maximafteniy" target="_blank" rel="noopener noreferrer">Maxim Afteniy</a></span> <a data-action="follow" data-user="260694711" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3872237104" data-role="relative-time" class="time-ago" title="Wednesday, April 25, 2018 7:46 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>I was citing this page, but I had to google your name XD.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3872237104" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1s1fh9s" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3872237104"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3872237104-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3828096946"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3828096946"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/maximafteniy/" data-action="profile" data-tab="" data-username="maximafteniy" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="260694711" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/maximafteniy/" data-action="profile" data-tab="" data-username="maximafteniy" target="_blank" rel="noopener noreferrer">Maxim Afteniy</a></span> <a data-action="follow" data-user="260694711" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3828096946" data-role="relative-time" class="time-ago" title="Wednesday, March 28, 2018 2:55 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>That was a great post! Do you have any recommendations on how to tune DQN agent hyperparameters proposed on Deepminds 2015 paper? (My agent doesnt seem to improve  with epsilon greedy and target network :/ )</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3828096946" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1rb5eia" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3828096946"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3828096946-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3811118737"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3811118737"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_mRTsB2KVj0/" data-action="profile" data-tab="" data-username="disqus_mRTsB2KVj0" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="283021196" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_mRTsB2KVj0/" data-action="profile" data-tab="" data-username="disqus_mRTsB2KVj0" target="_blank" rel="noopener noreferrer">HRL</a></span> <a data-action="follow" data-user="283021196" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3811118737" data-role="relative-time" class="time-ago" title="Saturday, March 17, 2018 11:39 PM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for the great post! This is very interesting. I thought it might be useful to share a paper for HRL from human demonstrations. Definitely, good priors help! <a href="https://disq.us/url?url=https%3A%2F%2Farxiv.org%2Fabs%2F1802.06604%3AGM35PrzdlW6CCUoQYX6UdIE-8vo&amp;cuid=3902136" rel="nofollow noopener" title="https://arxiv.org/abs/1802.06604">https://arxiv.org/abs/1802....</a></p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3811118737" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1r11i1d" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3811118737"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3811118737-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3787400513"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3787400513"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_JqSHarPgYx/" data-action="profile" data-tab="" data-username="disqus_JqSHarPgYx" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>G</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_JqSHarPgYx/" data-action="profile" data-tab="" data-username="disqus_JqSHarPgYx" target="_blank" rel="noopener noreferrer">Galahad Threepwood</a></span> <a data-action="follow" data-user="281845462" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3787400513" data-role="relative-time" class="time-ago" title="Monday, March 5, 2018 2:56 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Thanks for the great article. I was wondering if you could share you code testing the pendulum. I wanted to run that myself to see how bad the situation by tweaking around the parameters. Thanks!</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3787400513" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qmx4xt" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3787400513"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3787400513-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3781537278"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3781537278"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/junweidong/" data-action="profile" data-tab="" data-username="junweidong" target="_blank" rel="noopener noreferrer" class="user user--refresh"><div>J</div></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/junweidong/" data-action="profile" data-tab="" data-username="junweidong" target="_blank" rel="noopener noreferrer">Junwei Dong</a></span> <a data-action="follow" data-user="269387840" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3781537278" data-role="relative-time" class="time-ago" title="Thursday, March 1, 2018 9:43 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning --I read this paper before,  but I just can not figure out how to model game experience, so that using simulated experience would be possible.      Does someone know about it ?</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3781537278" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qjfgu6" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3781537278"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3781537278-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3775072212"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3775072212"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/disqus_SoX5cePsRu/" data-action="profile" data-tab="" data-username="disqus_SoX5cePsRu" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="191495189" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/disqus_SoX5cePsRu/" data-action="profile" data-tab="" data-username="disqus_SoX5cePsRu" target="_blank" rel="noopener noreferrer">Sarit</a></span> <a data-action="follow" data-user="191495189" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3775072212" data-role="relative-time" class="time-ago" title="Sunday, February 25, 2018 9:04 AM">6 years ago</a> </span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>This is really great.<br>it fits a discussion I was having with colleagues  about the AI industry and it's failure to truly represent the difficulties that exists mainly the lack of success in the various fields.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3775072212" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qfkwd0" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3775072212"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3775072212-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li><li class="post" id="post-3774008099"><div role="alert"></div><div data-role="post-content" class="post-content" tabindex="0"><div class="indicator"></div><span class="pinned-icon"></span><ul class="post-menu dropdown post-menu--refresh" data-role="menu" data-view-id="post-menu" data-post-id="3774008099"><li class="post-menu-item collapse"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Collapse" name="Collapse"><span>−</span></a></li><li class="post-menu-item expand"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="collapse" title="Expand" name="Collapse"><span>+</span></a></li><li class=" post-menu-item" role="menuitem"><a class="dropdown-toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="flag" data-role="flag" title="Flag as inappropriate"><i aria-hidden="true" class="icon icon-flag"></i></a></li></ul><div class="avatar hovercard"><a href="https://disqus.com/by/paulmcgee/" data-action="profile" data-tab="" data-username="paulmcgee" target="_blank" rel="noopener noreferrer" class="user user--refresh"><img data-role="user-avatar" data-user="55671418" src="./noavatar92.png" alt="Avatar" class="image-refresh"></a></div><div class="post-body"><header class="comment__header"><span class="post-byline"><span> <span class="author publisher-anchor-color"><a href="https://disqus.com/by/paulmcgee/" data-action="profile" data-tab="" data-username="paulmcgee" target="_blank" rel="noopener noreferrer">Paul McGee</a></span> <a data-action="follow" data-user="55671418" class="follow-user-container" tabindex="0"><span class="follow-user" aria-label="Follow" title="Follow"></span></a></span></span>  <span class="post-meta" style="display: block;"> <a href="https://www.alexirpan.com/2018/02/14/rl-hard.html#comment-3774008099" data-role="relative-time" class="time-ago" title="Saturday, February 24, 2018 4:02 PM">6 years ago</a> <span> <span class="has-edit" data-role="has-edit">edited</span></span></span> </header><div class="post-body-inner"><div class="post-message-container" data-role="message-container"><div class="publisher-anchor-color" data-role="message-content"><div class="post-message " data-role="message" dir="auto"><div><p>Do you know of anyone involving an animal trainer - the other reinforcement learning?  <br>Even 'though there is a reward function and thousands of trials, I suspect allowing a human to also add a "click-treat" at appropriate points might see a vastly faster shaping process and consistent success rates.</p></div></div><span class="post-media"><ul data-role="post-media-list"></ul></span></div></div><a class="see-more hidden" title="see more" data-action="see-more">see more</a></div><footer class="comment__footer"><menu class="comment-footer__menu"><li class="voting" data-role="voting"><div class="post-votes"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-up  count-0" data-action="upvote" title="Vote up" name="Vote up"><span class="control"></span> <span class="updatable count" data-role="likes">0</span></a><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="vote-down  count-0" data-action="downvote" title="Vote down" name="Vote down"><span class="control"></span> <span class="updatable count" data-role="dislikes">0</span></a></div></li><li class="reply" data-role="reply-link"><a class="comment-footer__action" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="reply"><span class="text">Reply</span></a></li><li id="comment__share-3774008099" class="comment__share"><a class="toggle" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="expand-share"><i class="icon icon-share"></i><span class="text">Share ›</span></a><ul class="comment-share__buttons"><div class="comment-share__social-share-buttons"><li class="twitter share__button-container"><button class="share__button icon icon-twitter-x" data-action="share:twitter" aria-label="Share comment on X (Twitter)"></button></li><li class="facebook share__button-container"><button class="share__button icon icon-facebook" data-action="share:facebook" aria-label="Share comment on Facebook"></button></li></div><li class="link share__button-container"><button class="share__button icon icon-link" value="http://disq.us/p/1qey3ab" name="Link" title="Click to copy post link" data-action="copy-link" aria-label="Copy link to comment"></button><input class="share__button link_url" name="Link" title="Click to copy post link" data-action="copy-link" readonly=""></li></ul></li><li class="realtime" data-role="realtime-notification:3774008099"><span class="realtime-replies realtime-replies--refresh icon icon-pencil" style="display: none;"></span><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" class="realtime-button realtime-button--refresh" style="display: none;"></a></li></menu></footer></div><div class="moderate-form blacklist-form" data-role="blacklist-form"></div><div class="moderate-form flag-form" data-role="flagging-form"></div><div class="badges-form" data-role="badges-form"></div><div class="reply-form-container" data-role="reply-form"></div></div><div class="children"><ul data-role="children"></ul><div class="show-children-wrapper hidden"><a class="show-children" id="post-3774008099-show-children" data-action="show-children" href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#">Show more replies</a></div></div></li></ul><div class="load-more-refresh load-more-refresh--v2" data-role="more" style=""><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" data-action="more-posts" class="btn load-more-refresh__button ">Load more comments</a></div></div></section><div id="placement-bottom" data-tracking-area="discovery-south"></div><footer id="footer" data-tracking-area="footer" class="disqus-footer__wrapper disqus-footer__wrapper--refresh"><div><div class="disqus-footer disqus-footer--refresh"><ul class="disqus-footer__list"><li id="thread-subscribe-button" class="email disqus-footer__item disqus-footer__item--refresh"><div class="default"><a href="https://disqus.com/embed/comments/?base=default&amp;f=kindasortainsightful&amp;t_i=%2F2018%2F02%2F14%2Frl-hard.html&amp;t_u=http%3A%2F%2Fwww.alexirpan.com%2F2018%2F02%2F14%2Frl-hard.html&amp;t_d=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;t_t=Deep%20Reinforcement%20Learning%20Doesn%27t%20Work%20Yet&amp;s_o=default#" rel="nofollow" data-action="subscribe" title="Subscribe and get email updates from this discussion" class="disqus-footer__link disqus-footer__link--refresh"><div class="icon-wrapper"><i aria-hidden="true" class="icon-subscribe-refresh"></i></div><i aria-hidden="true" class="icon icon-checkmark"></i><span id="thread-subscribe-text-default" class="text-item">Subscribe</span><span id="thread-subscribe-text-subscribed" class="text-item hidden">Subscribed</span></a></div></li><li class="privacy disqus-footer__item disqus-footer__item--refresh"><a href="https://disqus.com/privacy-policy" rel="nofollow noopener noreferrer" target="_blank" class="disqus-footer__link disqus-footer__link--refresh" title="Privacy"><div class="icon-wrapper"><i aria-hidden="true" class="icon-privacy-refresh"></i></div><span class="text-item">Privacy</span></a></li><li class="do-not-sell disqus-footer__item disqus-footer__item--refresh"><a href="https://disqus.com/data-sharing-settings/" rel="nofollow noopener noreferrer" target="_blank" class="disqus-footer__link disqus-footer__link--refresh"><div class="icon-wrapper"><i aria-hidden="true" class="icon-warning-refresh"></i></div><span class="text-item">Do Not Sell My Data</span></a></li></ul><span class="disqus-footer__logo"><a href="https://disqus.com/" rel="nofollow" title="Powered by Disqus" class="disqus-footer__link disqus-footer__link--refresh">Powered by Disqus</a></span></div></div></footer></div></div></div><div id="embed_v2-root"></div></div><div id=":r2:" data-floating-ui-portal=""><div class="_overlay_1i4qh_1" tabindex="-1" id=":r0:" role="listbox" style="position: fixed; left: 0px; top: 0px; transform: translate(62.4px, 140px); width: 678px;"></div></div></body></html>