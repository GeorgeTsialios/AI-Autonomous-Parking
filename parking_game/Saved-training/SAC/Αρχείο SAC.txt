~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					FIXED SPOT SPAWN (3 ή 8), RANDOM CAR SPAWN, INSTANT PARKING
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Training 1 <- PPO 47)

(1A) Δοκιμάζω τον SAC στο μοντέλο 47 του PPO. Μετά από 3.5Μ steps, η γραφική των rewards συγκλίνει σε θετική τιμή, ενώ το success rate συγκλίνει στο 45%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι όταν το αμάξι κανεί spawn με την όπισθεν προς τη θέση, τότε ο πράκτορας πάντα παρκάρει με την όπισθεν. Όμως, όταν το αμάξι κάνει spawn κοιτώντας τη θέση ή έστω παράλληλα, ο πράκτορας μένει ακίνητος. Στα 1000 επεισόδια αξιολόγησης, ο πράκτορας κατάφερε να παρκάρει σε 447 από αυτά. (1B) Αυξάνω το punishment for standing still. Επανεκπαιδεύω από το μοντέλο των 3300000 steps του 1A. Μετά από ακόμα 1Μ steps, παρατηρώ ότι η γραφική των rewards συγκλίνει σε χειρότερη τιμή με πριν, αλλά το success rate έχει αυξηθεί λίγο και συγκλίνει πλέον στο 50%. Για αυτό, (1C) επανεκπαιδεύω το μοντέλο των 4650000 steps με ακόμα μεγαλύτερο punishment for standing still. Η γραφική των rewards αρχικά μειώνεται κατακόρυφα, αλλά στη συνέχεια ο πράκτορας προσαρμόζεται και το average reward αυξάνεται. Μετά από 7Μ συνολικά steps, το success rate συγκλίνει στο 55%.

Training 2)  *COLAB*

Αλλάζω την max ταχύτητα του αμαξιού σε 4 και για μπροστά και για την όπισθεν. Έτσι, επιθυμώ να εξισορροπήσω την μπροστά κίνηση με την όπισθεν. Ωστόσο, μετά από 2.5M steps, η γραφική του success rate συγκλίνει στην τιμή 25%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι μένει συχνά ακίνητος, ενώ και πάλι δεν επιλέγει να κινηθεί προς τα εμπρός.

Training 4 <- 1) *COLAB*

Αυξάνω το punishment for standing still και προσθέτω rewards for moving forward, ώστε να μάθει να κινείται και προς τα εμπρός. Ήδη μετά από 3Μ steps, το reward συγκλίνει στην τιμή 4000 και το sucess rate συγκλίνει στο 90%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι παρκάρει σχεδόν πάντα και κάθε φορά με την όπισθεν.

Training 5)

(5A) Αυξάνω το reward for moving forward, ώστε να μάθει επιτέλους να παρκάρει και προς τα εμπρός. Μετά από 2Μ steps, το success rate συγκλίνει στο 75%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι έχει αναπτύξει την πολιτική του να κάνει τον γύρο του χάρτη κινούμενος προς τα εμπρός (γιατί επιβραβεύεται λίγο λόγω του for moving forward) και μετά να παρκάρει. Άρα, καταλαβαίνουμε πως πλέον το reward for moving forward είναι υπερβολικά ψηλό. (5B) Τώρα αυξάνω λιγότερο το reward for moving forward, ώστε να μάθει να παρκάρει και προς τα εμπρός, χωρίς όμως να κάνει και τον γύρο της πίστας κάθε φορά. Μετά από 4Μ steps, το success rate συγκλίνει στο 1. Εξετάζοντας τον πράκτορα, παρατηρώ ότι παρκάρει σχεδόν πάντα, τόσο με την όπισθεν όσο και προς τα μπροστά.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				RANDOM Spot Spawn (ΠΑΝΩ-ΚΑΤΩ), RANDOM Car Spawn, INSTANT Parking
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Training 7 <- 5B)

Δοκιμάζω τη reward function του μοντέλου 5Β. Μετά από 7Μ steps, παρατηρώ ότι η γραφική του success rate συγκλίνει στο 80%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι παρκάρει συχνά και με την όπισθεν και προς τα εμπρός χωρίς συγκρούσεις, όμως σε κάποια επεισόδια μένει ακίνητος. Το μοντέλο των 5.3M steps καταφέρνει να παρκάρει σε 83 από τα 100 επεισόδια αξιολόγησης.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				RANDOM Spot Spawn (ΟΠΟΙΟΔΗΠΟΤΕ RECTANGLE), RANDOM Car Spawn, INSTANT Parking
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Training 6 <- 5B) 

(6Α) Δοκιμάζω τη reward function του μοντέλου 5Β και FrameSkip=4 σε περιβάλλον με random spot spawn. Ωστόσο, μετά από 700K steps, παρατηρώ ότι η γραφική των rewards συγκλίνει σε αρνητική τιμή, ενώ το success rate συγκλίνει στο 0. Εξετάζοντας τον πράκτορα, παρατηρώ ότι έχει υιοθετήσει την πολιτική του να κάνει τον γύρο του χάρτη. 
(6Β) Αλλάζω την παράμετρο train_freq σε 4 (δηλ.ανά πόσα steps ενημερώνεται το μοντέλο). Μετά από 12M steps, το success rate τείνει στο 1. Εξετάζοντας τον πράκτορα, παρατηρώ ότι παρκάρει σχεδόν πάντα προς τα εμπρός και με την όπισθεν, αλλά μερικές φορές συγκρούεται με το περιβάλλον του.
(6C <- 6B) Δοκίμασα να αυξήσω το punishment for collisions από -10 σε -50, ώστε να μάθει να παρκάρει χωρίς να συγκρούεται. Μετά από 7Μ steps, οι γραφικές είναι παρόμοιες με πριν, αλλά εξετάζοντας τον πράκτορα, παρατηρώ ότι συγκρούεται συχνά. Δοκίμασα να το αυξήσω και σε -100 ωστόσο, μετά από 11Μ steps, το success rate συγκλίνει στο 30%.
(6D) Δοκιμάζω χωρίς FrameSkip. Ωστόσο, μετά από 3Μ steps, το success rate συγκλίνει στο 30%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι μένει συχνά ακίνητος ή κάνει τον γύρο του χάρτη. 
(6E) Αυξάνω το punishment for standing still και μειώνω το reward for moving forward, για να λύσω τα προηγούμενα προβλήματα. Ωστόσο, μετά από 600K steps, η γραφική των rewards συγκλίνει σε αρνητική τιμή, ενώ το success rate έχει πολύ μικρές τιμές. Εξετάζοντας τον πράκτορα, παρατηρώ ότι έχει υιοθετήσει την πολιτική του να κάνει τον γύρο του χάρτη. 
(6F <- 6C) Αυξάνω το punishment for standing still και προσθέτω στο reward for terminated reward for being in the right angle and close to the center of the spot. Ωστόσο, μετά από 200K steps, η γραφική των rewards συγκλίνει σε αρνητική τιμή, ενώ το success rate παραμένει 0.

Training 8 <- 7)

(8A) Δοκιμάζω Curriculum Learning με το μοντέλο των 5.3M steps της εκπαίδευσης 7. Ωστόσο, μετά από 1Μ steps το sucess rate συγκλίνει στο 0. Εξετάζοντας τον πράκτορα, παρατηρώ ότι μένει συχνά ακίνητος. (8Β)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				RANDOM Spot Spawn (ΟΠΟΙΟΔΗΠΟΤΕ RECTANGLE), RANDOM Car Spawn, NORMAL Parking
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Training 9 <- 6B)

Εκπαιδεύω με τη reward function της εκπαίδευσης 6Β, προσθέτοντας το κομμάτι elif inside spot (reward shaping). Ωστόσο, μετά από 3Μ steps, η γραφική των rewards συγκλίνει σε αρνητική τιμή, ενώ το success rate συγκλίνει στο 0. Εξετάζοντας τον πράκτορα, παρατηρώ ότι έχει υιοθετήσει την πολιτική του να κάνει τον γύρο του χάρτη.

Training 10 <- 6B)

Εφαρμόζω Curriculum Learning με το μοντέλο των 12M steps της εκπαίδευσης 6Β. Μετά από 8Μ steps, το success rate τείνει στο 95%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι παρκάρει σχεδόν πάντα, όμως συγκρούεται συχνά με το περιβάλλον.

Training 11 <- 10)

Αυξάνω το punishment for collision από -10 σε -1000 και εφαρμόζω Curriculum Learning με το μοντέλο των 6.1Μ steps της εκπαίδευσης 10 (94% success rate). Μετά από 8Μ steps το success rate συγκλίνει στο 80%. Εξετάζοντας τον πράκτορα, παρατηρώ ότι όταν παρκάρει με την όπισθεν συγκρούεται πρώτα κάθε φορά με τον κήπο, ενώ όταν παρκάρει προς τα εμπρός συγκρούεται σπάνια.

Training 12 <- 10)

(12Α) Αυξάνω το punishment for collision από -10 σε -3000, αλλάζω το reward for terminated ώστε να επιβραβεύεται με βάση την απόσταση και τη γωνία του και εφαρμόζω Curriculum Learning με το μοντέλο των 6.1Μ steps της εκπαίδευσης 10 (94% success rate). Όμως μετά από 2Μ steps, το success rate κυμαίνεται στο 15%. Παρατηρώντας τον πράκτορα, παρατηρώ ότι σπάνια προσπαθεί να παρκάρει, κι όταν το επιχειρεί κινείται πάρα πολύ αργά, για να μην συγκρουστεί.

Training 13 <- 11)

(13Α) Αυξάνω το punishment for collision από -1000 σε -2000 και εφαρμόζω Curriculum Learning με το μοντέλο των 7.3Μ steps της εκπαίδευσης 11 (83% success rate). Ωστόσο, μετά από 1.5Μ steps, το success rate κυμαίνεται στο 25%. (13Β)  Αυξάνω το punishment for collision από -1000 σε -1300 και εφαρμόζω Curriculum Learning με το μοντέλο των 7.3Μ steps της εκπαίδευσης 11 (83% success rate). Μετά από 11Μ steps, το success rate τείνει στο 75%.
