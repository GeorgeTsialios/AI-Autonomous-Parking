## Συμπεράσματα	{#sec:evaluation:conclusions}

Τα τελικά συμπεράσματα της εργασίας, τα οποία προκύπτουν από τα αποτελέσματα της σύγκρισης των αλγορίθμων, συνοψίζονται στα ακόλουθα σημεία:

- Ο αλγόριθμος **Q-Learning** είναι ο πιο υπολογιστικά φτηνός αλγόριθμος που εξετάστηκε, καθώς συγκλίνει σε σημαντικά λιγότερο χρόνο, σε σχέση με τους αλγορίθμους βαθιάς ενισχυτικής μάθησης. Ωστόσο, επιβεβαιώνεται πως δεν είναι κατάλληλος για προβλήματα μεγάλων διαστάσεων, καθώς παρά τη διακριτοποίηση του περιβάλλοντος, δεν κατάφερε να εκπαιδευτεί αποτελεσματικά, στο πρόβλημα της αυτόματης στάθμευσης.
- Ο αλγόριθμος βελτιστοποίησης πολιτικής **PPO** είναι πιο αποδοτικός στον χρόνο εκπαίδευσης, σε σχέση με τους αλγορίθμους της κατηγορίας δράστη-κριτή, αφού η μέση διάρκεια εκπαίδευσης του (και άρα, ο χρόνος σύγκλισης του) είναι αρκετά μικρότερη. Ωστόσο, το πρόβλημα της αυτόματης στάθμευσης, αποδείχθηκε πολύ δύσκολο για τον αλγόριθμο, κι επομένως απαιτήθηκαν μεγάλο πλήθος προσπαθειών και σημαντικός χρόνος εκπαίδευσης, για να φτάσει σε επιθυμητά αποτελέσματα. Ακόμα όμως κι έτσι, οι επιδόσεις του ήταν χειρότερες σε σχέση με τους αλγορίθμους δράστη-κριτή και τα αποτελέσματα του στο πραγματικό πρόβλημα της αυτόματης στάθμευσης (επίπεδο 4), δεν ήταν ικανοποιητικά.
- Ο αλγόριθμος **DDPG** επαληθεύεται πως είναι ο πιο απλός, της κατηγορίας δράστη-κριτή, αφού χρειάστηκε το μικρότερο χρόνο εκπαίδευσης, σε σχέση με τους άλλους δύο, ενώ ο χρόνος αυτός ήταν συγκρίσιμος με τον αντίστοιχο του PPO. Παράλληλα, προσφέρει τις αυξημένες επιδόσεις των αλγορίθμων δράστη-κριτή, ειδικότερα σε λιγότερο σύνθετα περιβάλλοντα. Συγκεκριμένα, στο πρόβλημα της άμεσης στάθμευσης, τα αποτελέσματα του DDPG ήταν εφάμιλλα με αυτά του καλύτερου αλγορίθμου (TD3), αλλά στο πρόβλημα της κανονικής στάθμευσης, οι επιδόσεις του αλγορίθμου μειώθηκαν δραστικά. Επομένως, ο αλγόριθμος DDPG κρίνεται ως μία καλή μέση λύση, μεταξύ χρόνου εκπαίδευσης και επιδόσεων και συνιστάται για απλούστερα προβλήματα.
- Ο αλγόριθμος **SAC** αποδείχθηκε πως βρίσκεται στο ενδιάμεσο μεταξύ του DDPG και του TD3, όσον αφορά τον απαιτούμενο χρόνο εκπαίδευσης του. Οι επιδόσεις του στα προβλήματα της άμεσης και της κανονικής στάθμευσης μπορεί να μην ήταν στο επίπεδο του TD3, ήταν όμως αρκετά υψηλές και σταθερές και στα δύο προβλήματα. Επομένως, ο αλγόριθμος SAC είναι μία αξιόπιστη λύση, ικανή να εφαρμοστεί ακόμα και σε πιο πολύπλοκα περιβάλλοντα.
- Ο αλγόριθμος **TD3** επιβεβαιώνεται πως αποτελεί με διαφορά, τον πιο κοστοβόρο αλγόριθμο της κατηγορίας δράστη-κριτή. Παρόλα αυτά, οι επιδόσεις του αλγορίθμου, αντισταθμίζουν το αυξημένο υπολογιστικό του κόστος. Συγκεκριμένα, ο αλγόριθμος TD3 πέτυχε τα καλύτερα αποτελέσματα και στα δύο περιβάλλοντα που εξετάστηκαν. Μάλιστα, στο δυσκολότερο πρόβλημα της κανονικής στάθμευσης, οι επιδόσεις του αλγορίθμου προσέγγισαν με μεγάλη ακρίβεια τις ανθρώπινες. Επομένως, ο αλγόριθμος TD3, παρά τις απαιτήσεις του σε υπολογιστικούς πόρους, αποτελεί την καλύτερη επιλογή για το πρόβλημα της αυτόματης στάθμευσης.