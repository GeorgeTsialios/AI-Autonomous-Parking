# Μελλοντικές Βελτιώσεις {#sec:future-work}

Ο στόχος που τέθηκε για την παρούσα εργασία επετεύχθη, καθώς διεξήχθη μία τεκμηριωμένη σύγκριση διαφορετικών αλγορίθμων ενισχυτικής μάθησης. Μάλιστα, οι πράκτορες που αναπτύχθηκαν στα πλαίσια της εργασίας, έφτασαν σε επίπεδα επιδόσεων που προσεγγίζουν το ανθρώπινο. Ωστόσο, υπάρχουν πολλοί τρόποι με τους οποίους η εργασία αυτή μπορεί να βελτιωθεί ή και να επεκταθεί. Στη συνέχεια, παρουσιάζονται μερικές ιδέες για μελλοντική έρευνα και εξέλιξη της εργασίας, οι οποίες δεν υλοποιήθηκαν, λόγω χρονικών περιορισμών.

Αρχικά, υπάρχει χώρος για βελτίωση στο κομμάτι του περιβάλλοντος των εκπαιδεύσεων. Συγκεκριμένα, μπορεί να αξιοποιηθεί κάποια βιβλιοθήκη φυσικής, ώστε να προσομοιωθούν με μεγαλύτερη ακρίβεια, μηχανισμοί όπως η κίνηση του αυτοκινήτου και οι συγκρούσεις του. Άκομα, χρήσιμη θα ήταν η υλοποίηση ενός πιο σύνθετου και ακριβέστερου τύπου αισθητήρα, σε σχέση με τις ακτίνες ραντάρ (*raycasts*), όπως για παράδειγμα οι ακτίνες κουτιού (*boxcasts*) ή σφαίρας (*spherecasts*). Τέλος, μπορεί να σχεδιαστεί ένας εξ ολοκλήρου νέος χάρτης παιχνιδιού, στον οποίο θα εξετάζεται το σαφώς δυσκολότερο πρόβλημα της παράλληλης στάθμευσης. 

Στη συνέχεια, στο κομμάτι των αλγορίθμων ενισχυτικής μάθησης, μπορούν να δοκιμαστούν νέες μέθοδοι και εργαλεία. Για παράδειγμα, η τεχνική των βοηθητικών σημάτων ανταμοιβής (*auxiliary reward signals*), όπως το εγγενές σήμα της «περιέργειας» (*intrinsic curiosity*), μπορεί να χρησιμοποιηθεί για την ενθάρρυνση της εξερεύνησης του πράκτορα. Αντίστοιχα, η μέθοδος της επανάληψη εμπειρίας (*experience replay*), μπορεί να αυξήσει τη σταθερότητα και την αποδοτικότητα της εκπαίδευσης. Τέλος, η χρήση ενός λογισμικού αυτόματης βελτιστοποίησης υπερπαραμέτρων μηχανικής μάθησης, όπως το [Optuna](https://optuna.org/), ίσως βελτιώσει τα αποτελέσματα της εκπαίδευσης.

Πέραν όμως των αλγορίθμων που ήδη αναλύθηκαν σε αυτήν την εργασία, το πρόβλημα της αυτόματης στάθμευσης μπορεί να επεκταθεί και σε άλλες κατηγορίες αλγορίθμων. Δύο πολύ ενδιαφέρουσες τεχνικές μηχανικής μάθησης που θα μπορούσαν να εφαρμοστούν, είναι η μάθηση με μίμηση (*imitation learning*) και οι γενετικοί αλγόριθμοι (*genetic algorithms*). 

Στη μάθηση με μίμηση, ο πράκτορας αναπτύσσει την πολιτική του, αντιγράφοντας τη συμπεριφορά ενός ανθρώπου ειδικού, μέσω παρατηρήσεων ζευγών κατάστασης-ενέργειας. Ωστόσο, μέσα από αυτήν τη διαδικασία, ο πράκτορας μπορεί μόνο να αναπαράγει την επίδοση του ειδικού και όχι να την υπερβεί. Έτσι, πολλές φορές η μάθηση με μίμηση χρησιμοποιείται σε συνδυασμό με την ενισχυτική μάθηση, ώστε να επιταχυνθεί η διαδικασία εκπαίδευσης στα πρώτα στάδια της, αλλά και να βελτιωθεί η τελική επίδοση του πράκτορα.

Από την άλλη, οι γενετικοί αλγόριθμοι είναι μία κατηγορία αλγορίθμων βελτιστοποίησης, οι οποίοι εμπνέονται από την εξέλιξη των ειδών στη φύση. Συγκεκριμένα, δημιουργείται ένας πληθυσμός υποψηφίων λύσεων, ο οποίος εξελίσσεται μέσα από διαδικασίες όπως η επιλογή (*selection*), η διασταύρωση (*crossover*) και η μετάλλαξη (*mutation*). Αποτελούν μία ιδιαίτερα δημοφιλή επιλογή για την εκπαίδευση πρακτόρων σε παιχνίδια αγώνων ταχύτητας (*racing games*), άλλα συναντώνται σπανιότερα σε προβλήματα αυτόματης στάθμευσης. Αυτο μάλλον οφείλεται στη δυσκολία του συγκεκριμένου προβλήματος, αφού πρόκειται για ένα περιβάλλον με αραιές ανταμοιβές. Οι γενετικοί αλγόριθμοι δεν είναι κατάλληλοι για τέτοια περιβάλλοντα, καθώς η ανατροφοδότηση στους πράκτορες τους, δίνεται μόνο στο τέλος κάθε γενιάς και όχι μετά από κάθε ενέργεια, όπως στην ενισχυτική μάθηση. Ο παράγοντας αυτός, σε συνδυασμό με το αυξημένο υπολογιστικό κόστος τους, οδήγησε στην προτίμηση άλλων μεθόδων στην παρούσα εργασία. Παρόλα αυτά, ο πειραματισμός με αυτούς τους αλγορίθμους θα μπορούσε να αποτελέσει μία ενδιαφέρουσα κατεύθυνση για μελλοντική έρευνα.